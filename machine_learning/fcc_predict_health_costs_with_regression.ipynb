{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fcc_predict_health_costs_with_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokymok/freecodecamp_projects/blob/main/machine_learning/fcc_predict_health_costs_with_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TX15KOkPBV"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the `train_dataset` and 20% of the data as the `test_dataset`.\n",
        "\n",
        "`pop` off the \"expenses\" column from these datasets to create new datasets called `train_labels` and `test_labels`. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the `train_dataset`. Run the final cell in this notebook to check your model. The final cell will use the unseen `test_dataset` to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, `model.evaluate` must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the `test_dataset` and graph the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c69f022-6ff6-45d8-e6a0-ce250936424d"
      },
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Built wheel for tensorflow-docs is invalid: Metadata 1.2 mandates PEP 440 version, but '0.0.0cefa2f092b60fa8b89a1fbea3d4f029b3bd65b9a-' is not\u001b[0m\n",
            "    Running setup.py install for tensorflow-docs ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: tensorflow-docs was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7f5f6dcf-a8a2-4841-c7d4-3fb174c39f76"
      },
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-10 20:53:46--  https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 172.67.70.149, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50264 (49K) [text/csv]\n",
            "Saving to: ‘insurance.csv’\n",
            "\n",
            "insurance.csv       100%[===================>]  49.09K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-08-10 20:53:46 (6.78 MB/s) - ‘insurance.csv’ saved [50264/50264]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>expenses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex   bmi  children smoker     region  expenses\n",
              "1333   50    male  31.0         3     no  northwest  10600.55\n",
              "1334   18  female  31.9         0     no  northeast   2205.98\n",
              "1335   18  female  36.9         0     no  southeast   1629.83\n",
              "1336   21  female  25.8         0     no  southwest   2007.95\n",
              "1337   61  female  29.1         0    yes  northwest  29141.36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "i-peKta01p1Z",
        "outputId": "5466425d-28b4-4cb2-ad26-256045d784d6"
      },
      "source": [
        "catColumns = [\"sex\", \"smoker\", \"region\"]\n",
        "dataset = pd.get_dummies(dataset, columns = catColumns, drop_first=True)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>expenses</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.9</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.7</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age   bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.9         0  ...                 0                 0                 1\n",
              "1   18  33.8         1  ...                 0                 1                 0\n",
              "2   28  33.0         3  ...                 0                 1                 0\n",
              "3   33  22.7         0  ...                 1                 0                 0\n",
              "4   32  28.9         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfnusffP1oFp"
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "test_labels = test_dataset.pop(\"expenses\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "vCsQL3xI1luJ",
        "outputId": "69407a53-450f-418d-8f7e-40ff0eba83e8"
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>39.036449</td>\n",
              "      <td>14.142122</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>30.737290</td>\n",
              "      <td>6.065193</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>30.5</td>\n",
              "      <td>34.8</td>\n",
              "      <td>53.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>1.093458</td>\n",
              "      <td>1.211364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex_male</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.498131</td>\n",
              "      <td>0.500230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker_yes</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.199065</td>\n",
              "      <td>0.399484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_northwest</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.235514</td>\n",
              "      <td>0.424518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southeast</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.281308</td>\n",
              "      <td>0.449848</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region_southwest</th>\n",
              "      <td>1070.0</td>\n",
              "      <td>0.234579</td>\n",
              "      <td>0.423934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   count       mean        std   min   25%   50%   75%   max\n",
              "age               1070.0  39.036449  14.142122  18.0  26.0  39.0  51.0  64.0\n",
              "bmi               1070.0  30.737290   6.065193  16.0  26.3  30.5  34.8  53.1\n",
              "children          1070.0   1.093458   1.211364   0.0   0.0   1.0   2.0   5.0\n",
              "sex_male          1070.0   0.498131   0.500230   0.0   0.0   0.0   1.0   1.0\n",
              "smoker_yes        1070.0   0.199065   0.399484   0.0   0.0   0.0   0.0   1.0\n",
              "region_northwest  1070.0   0.235514   0.424518   0.0   0.0   0.0   0.0   1.0\n",
              "region_southeast  1070.0   0.281308   0.449848   0.0   0.0   0.0   1.0   1.0\n",
              "region_southwest  1070.0   0.234579   0.423934   0.0   0.0   0.0   0.0   1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX3eoo_f1kCB"
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcopvQh3X-kX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704ede44-23e3-4184-aa86-064891d970f1"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1, activation='relu')\n",
        "  ])\n",
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "model.compile(loss='mae',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['mae','mse'])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1152      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 16,193\n",
            "Trainable params: 16,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-kXgD5D1hbK",
        "outputId": "76b6380c-79ff-48f8-e8de-e0df14b1dad2"
      },
      "source": [
        "EPOCHS = 1000\n",
        "history = model.fit(train_dataset, train_labels, epochs=EPOCHS, validation_split = 0.2, verbose=1, callbacks=[tf.keras.callbacks.ModelCheckpoint(\"./checkpoint\", save_best_only=True, monitor='val_loss')])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "27/27 [==============================] - 4s 11ms/step - loss: 12454.9521 - mae: 12454.9521 - mse: 295063712.0000 - val_loss: 13422.2783 - val_mae: 13422.2783 - val_mse: 334026880.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 2/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 9830.5439 - mae: 9830.5439 - mse: 228115472.0000 - val_loss: 8672.5215 - val_mae: 8672.5215 - val_mse: 207707168.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 3/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7187.6997 - mae: 7187.6997 - mse: 149768272.0000 - val_loss: 7874.0659 - val_mae: 7874.0659 - val_mse: 180454928.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 4/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7022.1455 - mae: 7022.1455 - mse: 146893520.0000 - val_loss: 7772.3643 - val_mae: 7772.3643 - val_mse: 170407712.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 5/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6950.0264 - mae: 6950.0264 - mse: 145463520.0000 - val_loss: 7676.4111 - val_mae: 7676.4111 - val_mse: 181270528.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 6/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6833.1914 - mae: 6833.1914 - mse: 147512816.0000 - val_loss: 7566.7310 - val_mae: 7566.7310 - val_mse: 178938352.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 7/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6753.0898 - mae: 6753.0898 - mse: 147343360.0000 - val_loss: 7580.8833 - val_mae: 7580.8833 - val_mse: 188384080.0000\n",
            "Epoch 8/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6636.8213 - mae: 6636.8213 - mse: 149059072.0000 - val_loss: 7494.3306 - val_mae: 7494.3306 - val_mse: 190196880.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 9/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6542.1001 - mae: 6542.1001 - mse: 150627952.0000 - val_loss: 7352.1299 - val_mae: 7352.1299 - val_mse: 187182544.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 10/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6462.9873 - mae: 6462.9873 - mse: 151742304.0000 - val_loss: 7289.0674 - val_mae: 7289.0674 - val_mse: 188413824.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 11/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6398.2852 - mae: 6398.2852 - mse: 152395728.0000 - val_loss: 7470.6455 - val_mae: 7470.6455 - val_mse: 199566384.0000\n",
            "Epoch 12/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6374.1597 - mae: 6374.1597 - mse: 154526880.0000 - val_loss: 7230.8120 - val_mae: 7230.8120 - val_mse: 189824832.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 13/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6324.9443 - mae: 6324.9443 - mse: 153518704.0000 - val_loss: 7243.8306 - val_mae: 7243.8306 - val_mse: 193256512.0000\n",
            "Epoch 14/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6323.4829 - mae: 6323.4829 - mse: 154255280.0000 - val_loss: 7204.5913 - val_mae: 7204.5913 - val_mse: 187343152.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 15/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6302.3877 - mae: 6302.3877 - mse: 153482064.0000 - val_loss: 7192.0620 - val_mae: 7192.0620 - val_mse: 190801552.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 16/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6288.9712 - mae: 6288.9712 - mse: 153503872.0000 - val_loss: 7200.5234 - val_mae: 7200.5234 - val_mse: 192579744.0000\n",
            "Epoch 17/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6263.0928 - mae: 6263.0928 - mse: 152771280.0000 - val_loss: 7183.2061 - val_mae: 7183.2061 - val_mse: 192141216.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 18/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6251.7476 - mae: 6251.7476 - mse: 152763296.0000 - val_loss: 7147.7104 - val_mae: 7147.7104 - val_mse: 188772608.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 19/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6231.8413 - mae: 6231.8413 - mse: 151386624.0000 - val_loss: 7192.4424 - val_mae: 7192.4424 - val_mse: 193560864.0000\n",
            "Epoch 20/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6206.3701 - mae: 6206.3701 - mse: 151559680.0000 - val_loss: 7125.7183 - val_mae: 7125.7183 - val_mse: 185159312.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 21/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6213.7090 - mae: 6213.7090 - mse: 150181392.0000 - val_loss: 7254.0483 - val_mae: 7254.0483 - val_mse: 196162768.0000\n",
            "Epoch 22/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6198.7974 - mae: 6198.7974 - mse: 150924352.0000 - val_loss: 7146.4976 - val_mae: 7146.4976 - val_mse: 192377632.0000\n",
            "Epoch 23/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6182.0039 - mae: 6182.0039 - mse: 151080448.0000 - val_loss: 7076.7104 - val_mae: 7076.7104 - val_mse: 184318080.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 24/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6172.2383 - mae: 6172.2383 - mse: 149910288.0000 - val_loss: 7067.6313 - val_mae: 7067.6313 - val_mse: 182523504.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 25/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6162.3330 - mae: 6162.3330 - mse: 149541120.0000 - val_loss: 7178.3691 - val_mae: 7178.3691 - val_mse: 193817088.0000\n",
            "Epoch 26/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6133.3770 - mae: 6133.3770 - mse: 149573440.0000 - val_loss: 7076.5425 - val_mae: 7076.5425 - val_mse: 178438960.0000\n",
            "Epoch 27/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6125.8252 - mae: 6125.8252 - mse: 148521264.0000 - val_loss: 7053.4766 - val_mae: 7053.4766 - val_mse: 189030592.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 28/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6089.1221 - mae: 6089.1221 - mse: 148155664.0000 - val_loss: 6990.6421 - val_mae: 6990.6421 - val_mse: 185101632.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 29/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6076.9653 - mae: 6076.9653 - mse: 147775472.0000 - val_loss: 6961.1240 - val_mae: 6961.1240 - val_mse: 180499984.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 30/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6075.2285 - mae: 6075.2285 - mse: 146982464.0000 - val_loss: 6941.1987 - val_mae: 6941.1987 - val_mse: 182708208.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 31/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6042.4521 - mae: 6042.4521 - mse: 146358816.0000 - val_loss: 6914.8018 - val_mae: 6914.8018 - val_mse: 180085344.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 32/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6028.6064 - mae: 6028.6064 - mse: 145621648.0000 - val_loss: 6937.1641 - val_mae: 6937.1641 - val_mse: 184809472.0000\n",
            "Epoch 33/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6005.2134 - mae: 6005.2134 - mse: 145097216.0000 - val_loss: 6873.2588 - val_mae: 6873.2588 - val_mse: 180894160.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 34/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5962.0107 - mae: 5962.0107 - mse: 143553104.0000 - val_loss: 6900.7256 - val_mae: 6900.7256 - val_mse: 183336112.0000\n",
            "Epoch 35/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5970.2915 - mae: 5970.2915 - mse: 143613408.0000 - val_loss: 6811.2642 - val_mae: 6811.2642 - val_mse: 178312560.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 36/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5931.9399 - mae: 5931.9399 - mse: 142293648.0000 - val_loss: 6779.5396 - val_mae: 6779.5396 - val_mse: 171671280.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 37/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5896.8770 - mae: 5896.8770 - mse: 140668320.0000 - val_loss: 6739.5571 - val_mae: 6739.5571 - val_mse: 175173152.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 38/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5872.6440 - mae: 5872.6440 - mse: 139692080.0000 - val_loss: 6698.4429 - val_mae: 6698.4429 - val_mse: 173108976.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 39/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5845.5068 - mae: 5845.5068 - mse: 138418528.0000 - val_loss: 6658.9028 - val_mae: 6658.9028 - val_mse: 168377920.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 40/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5832.2451 - mae: 5832.2451 - mse: 137056688.0000 - val_loss: 6615.1279 - val_mae: 6615.1279 - val_mse: 168205264.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 41/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5778.6001 - mae: 5778.6001 - mse: 135984208.0000 - val_loss: 6574.5771 - val_mae: 6574.5771 - val_mse: 167693488.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 42/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5758.1260 - mae: 5758.1260 - mse: 134048216.0000 - val_loss: 6525.8540 - val_mae: 6525.8540 - val_mse: 163581568.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 43/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5698.1372 - mae: 5698.1372 - mse: 132464256.0000 - val_loss: 6496.8691 - val_mae: 6496.8691 - val_mse: 165081280.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 44/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5666.3042 - mae: 5666.3042 - mse: 129573416.0000 - val_loss: 6451.6011 - val_mae: 6451.6011 - val_mse: 163395904.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 45/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5625.5869 - mae: 5625.5869 - mse: 128914976.0000 - val_loss: 6462.1821 - val_mae: 6462.1821 - val_mse: 149594784.0000\n",
            "Epoch 46/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5563.2236 - mae: 5563.2236 - mse: 125727728.0000 - val_loss: 6279.4551 - val_mae: 6279.4551 - val_mse: 153421888.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 47/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5525.6982 - mae: 5525.6982 - mse: 123324744.0000 - val_loss: 6226.2266 - val_mae: 6226.2266 - val_mse: 152674928.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 48/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5449.3003 - mae: 5449.3003 - mse: 121914336.0000 - val_loss: 6129.5898 - val_mae: 6129.5898 - val_mse: 144364176.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 49/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5372.5542 - mae: 5372.5542 - mse: 117936944.0000 - val_loss: 6076.2583 - val_mae: 6076.2583 - val_mse: 137376848.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 50/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5289.9810 - mae: 5289.9810 - mse: 113496792.0000 - val_loss: 5898.2051 - val_mae: 5898.2051 - val_mse: 138138416.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 51/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5202.4126 - mae: 5202.4126 - mse: 109194736.0000 - val_loss: 6140.9141 - val_mae: 6140.9141 - val_mse: 143433152.0000\n",
            "Epoch 52/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5090.7114 - mae: 5090.7114 - mse: 104253648.0000 - val_loss: 5899.4238 - val_mae: 5899.4238 - val_mse: 135209568.0000\n",
            "Epoch 53/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4937.6841 - mae: 4937.6841 - mse: 99259552.0000 - val_loss: 5394.4810 - val_mae: 5394.4810 - val_mse: 114439792.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 54/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4767.0161 - mae: 4767.0161 - mse: 90212616.0000 - val_loss: 5323.6284 - val_mae: 5323.6284 - val_mse: 100805008.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 55/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4546.9238 - mae: 4546.9238 - mse: 83216864.0000 - val_loss: 5605.6641 - val_mae: 5605.6641 - val_mse: 114051472.0000\n",
            "Epoch 56/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4390.4688 - mae: 4390.4688 - mse: 76126944.0000 - val_loss: 4645.9712 - val_mae: 4645.9712 - val_mse: 91108904.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 57/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4145.6533 - mae: 4145.6533 - mse: 69806048.0000 - val_loss: 4526.5322 - val_mae: 4526.5322 - val_mse: 76365488.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 58/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4001.3779 - mae: 4001.3779 - mse: 64449424.0000 - val_loss: 4245.8306 - val_mae: 4245.8306 - val_mse: 73347912.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 59/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3870.0864 - mae: 3870.0864 - mse: 58356824.0000 - val_loss: 4164.1929 - val_mae: 4164.1929 - val_mse: 71976184.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 60/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3811.6907 - mae: 3811.6907 - mse: 57182480.0000 - val_loss: 4042.1111 - val_mae: 4042.1111 - val_mse: 64875540.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 61/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3772.9990 - mae: 3772.9990 - mse: 54105452.0000 - val_loss: 3967.1040 - val_mae: 3967.1040 - val_mse: 63238044.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 62/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3763.2966 - mae: 3763.2966 - mse: 52051740.0000 - val_loss: 3935.1799 - val_mae: 3935.1799 - val_mse: 60134956.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 63/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3624.1804 - mae: 3624.1804 - mse: 50747808.0000 - val_loss: 4043.5657 - val_mae: 4043.5657 - val_mse: 63982552.0000\n",
            "Epoch 64/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3717.3928 - mae: 3717.3928 - mse: 51107036.0000 - val_loss: 3944.7065 - val_mae: 3944.7065 - val_mse: 57138044.0000\n",
            "Epoch 65/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3677.0415 - mae: 3677.0415 - mse: 49635796.0000 - val_loss: 4202.9780 - val_mae: 4202.9780 - val_mse: 63669248.0000\n",
            "Epoch 66/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3614.5671 - mae: 3614.5671 - mse: 46671376.0000 - val_loss: 4082.5476 - val_mae: 4082.5474 - val_mse: 52255308.0000\n",
            "Epoch 67/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3582.9451 - mae: 3582.9451 - mse: 46647656.0000 - val_loss: 3952.0244 - val_mae: 3952.0244 - val_mse: 51346184.0000\n",
            "Epoch 68/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3617.3806 - mae: 3617.3806 - mse: 44180916.0000 - val_loss: 4390.6909 - val_mae: 4390.6909 - val_mse: 60710552.0000\n",
            "Epoch 69/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3660.0146 - mae: 3660.0146 - mse: 43856388.0000 - val_loss: 4001.8438 - val_mae: 4001.8438 - val_mse: 55484644.0000\n",
            "Epoch 70/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3608.2161 - mae: 3608.2161 - mse: 44626684.0000 - val_loss: 3978.7793 - val_mae: 3978.7793 - val_mse: 47636960.0000\n",
            "Epoch 71/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3611.8318 - mae: 3611.8318 - mse: 43762620.0000 - val_loss: 4245.0801 - val_mae: 4245.0801 - val_mse: 55595208.0000\n",
            "Epoch 72/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3544.8557 - mae: 3544.8557 - mse: 41607072.0000 - val_loss: 4398.3354 - val_mae: 4398.3354 - val_mse: 55943188.0000\n",
            "Epoch 73/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3527.2971 - mae: 3527.2971 - mse: 41232296.0000 - val_loss: 3680.3230 - val_mae: 3680.3230 - val_mse: 46574416.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 74/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3553.0088 - mae: 3553.0088 - mse: 40297600.0000 - val_loss: 4195.6807 - val_mae: 4195.6807 - val_mse: 42708596.0000\n",
            "Epoch 75/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3541.5750 - mae: 3541.5750 - mse: 38420400.0000 - val_loss: 3830.6995 - val_mae: 3830.6995 - val_mse: 42483264.0000\n",
            "Epoch 76/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3512.6277 - mae: 3512.6277 - mse: 38500192.0000 - val_loss: 3761.7131 - val_mae: 3761.7131 - val_mse: 45009944.0000\n",
            "Epoch 77/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3429.8105 - mae: 3429.8105 - mse: 37388016.0000 - val_loss: 4038.2676 - val_mae: 4038.2676 - val_mse: 45958484.0000\n",
            "Epoch 78/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3498.2007 - mae: 3498.2007 - mse: 37710556.0000 - val_loss: 3602.5466 - val_mae: 3602.5466 - val_mse: 40966152.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 79/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3469.4004 - mae: 3469.4004 - mse: 37385164.0000 - val_loss: 3646.7156 - val_mae: 3646.7156 - val_mse: 41053996.0000\n",
            "Epoch 80/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3380.2146 - mae: 3380.2146 - mse: 36931268.0000 - val_loss: 3735.0957 - val_mae: 3735.0957 - val_mse: 40163504.0000\n",
            "Epoch 81/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3445.1729 - mae: 3445.1729 - mse: 37386988.0000 - val_loss: 3537.3335 - val_mae: 3537.3335 - val_mse: 40527268.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 82/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3395.0627 - mae: 3395.0627 - mse: 37813884.0000 - val_loss: 3425.1780 - val_mae: 3425.1780 - val_mse: 41432796.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 83/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3358.8774 - mae: 3358.8774 - mse: 37996684.0000 - val_loss: 4085.4475 - val_mae: 4085.4475 - val_mse: 45213924.0000\n",
            "Epoch 84/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3309.1592 - mae: 3309.1592 - mse: 38661652.0000 - val_loss: 4038.3108 - val_mae: 4038.3108 - val_mse: 43889760.0000\n",
            "Epoch 85/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3319.4048 - mae: 3319.4048 - mse: 39332080.0000 - val_loss: 3796.0344 - val_mae: 3796.0344 - val_mse: 43581324.0000\n",
            "Epoch 86/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3242.8889 - mae: 3242.8889 - mse: 38855060.0000 - val_loss: 3770.4565 - val_mae: 3770.4565 - val_mse: 43929144.0000\n",
            "Epoch 87/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3297.4304 - mae: 3297.4304 - mse: 39126224.0000 - val_loss: 3244.3477 - val_mae: 3244.3477 - val_mse: 42158008.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 88/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3248.6631 - mae: 3248.6631 - mse: 39548616.0000 - val_loss: 3399.9697 - val_mae: 3399.9697 - val_mse: 43414572.0000\n",
            "Epoch 89/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3276.3289 - mae: 3276.3289 - mse: 40183940.0000 - val_loss: 3740.2832 - val_mae: 3740.2832 - val_mse: 42188416.0000\n",
            "Epoch 90/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3188.3896 - mae: 3188.3896 - mse: 39077684.0000 - val_loss: 3815.5369 - val_mae: 3815.5369 - val_mse: 44394236.0000\n",
            "Epoch 91/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3257.3201 - mae: 3257.3201 - mse: 39972224.0000 - val_loss: 3489.0178 - val_mae: 3489.0178 - val_mse: 41570164.0000\n",
            "Epoch 92/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3258.6633 - mae: 3258.6633 - mse: 40362256.0000 - val_loss: 3367.3083 - val_mae: 3367.3083 - val_mse: 41916324.0000\n",
            "Epoch 93/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3176.6865 - mae: 3176.6865 - mse: 40068692.0000 - val_loss: 3188.4133 - val_mae: 3188.4133 - val_mse: 39593024.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 94/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3216.5735 - mae: 3216.5735 - mse: 39086004.0000 - val_loss: 3181.2126 - val_mae: 3181.2126 - val_mse: 42960804.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 95/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3180.2256 - mae: 3180.2256 - mse: 38530556.0000 - val_loss: 3711.2336 - val_mae: 3711.2336 - val_mse: 45365316.0000\n",
            "Epoch 96/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3161.4714 - mae: 3161.4714 - mse: 39075844.0000 - val_loss: 3244.4106 - val_mae: 3244.4106 - val_mse: 42175468.0000\n",
            "Epoch 97/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3165.0688 - mae: 3165.0688 - mse: 39165980.0000 - val_loss: 3636.5652 - val_mae: 3636.5652 - val_mse: 42355912.0000\n",
            "Epoch 98/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3197.4482 - mae: 3197.4482 - mse: 39244872.0000 - val_loss: 3277.9238 - val_mae: 3277.9238 - val_mse: 39271188.0000\n",
            "Epoch 99/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3177.0449 - mae: 3177.0449 - mse: 38240388.0000 - val_loss: 3566.7808 - val_mae: 3566.7808 - val_mse: 39918452.0000\n",
            "Epoch 100/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3191.7959 - mae: 3191.7959 - mse: 38792328.0000 - val_loss: 3131.3687 - val_mae: 3131.3687 - val_mse: 40218256.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 101/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3147.3794 - mae: 3147.3794 - mse: 37882068.0000 - val_loss: 3980.8181 - val_mae: 3980.8181 - val_mse: 47670704.0000\n",
            "Epoch 102/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3183.1462 - mae: 3183.1462 - mse: 38924488.0000 - val_loss: 3183.7410 - val_mae: 3183.7410 - val_mse: 38504048.0000\n",
            "Epoch 103/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3139.0601 - mae: 3139.0601 - mse: 38763244.0000 - val_loss: 3063.1470 - val_mae: 3063.1470 - val_mse: 40800248.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 104/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3140.0566 - mae: 3140.0564 - mse: 39100340.0000 - val_loss: 3518.4446 - val_mae: 3518.4446 - val_mse: 38389048.0000\n",
            "Epoch 105/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3100.9839 - mae: 3100.9839 - mse: 36343340.0000 - val_loss: 3694.3887 - val_mae: 3694.3887 - val_mse: 40211136.0000\n",
            "Epoch 106/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3166.0720 - mae: 3166.0720 - mse: 38502064.0000 - val_loss: 3336.9119 - val_mae: 3336.9119 - val_mse: 41193816.0000\n",
            "Epoch 107/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3096.4194 - mae: 3096.4194 - mse: 38005940.0000 - val_loss: 3397.9080 - val_mae: 3397.9080 - val_mse: 38246980.0000\n",
            "Epoch 108/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3071.4094 - mae: 3071.4094 - mse: 37342148.0000 - val_loss: 2970.2168 - val_mae: 2970.2168 - val_mse: 38055372.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 109/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3057.5459 - mae: 3057.5459 - mse: 36920372.0000 - val_loss: 3277.1428 - val_mae: 3277.1428 - val_mse: 37451308.0000\n",
            "Epoch 110/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3096.2996 - mae: 3096.2996 - mse: 37098048.0000 - val_loss: 3192.2542 - val_mae: 3192.2542 - val_mse: 36640116.0000\n",
            "Epoch 111/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3042.1140 - mae: 3042.1140 - mse: 37497276.0000 - val_loss: 3113.2673 - val_mae: 3113.2673 - val_mse: 37007836.0000\n",
            "Epoch 112/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3032.3472 - mae: 3032.3472 - mse: 36214884.0000 - val_loss: 3220.9683 - val_mae: 3220.9683 - val_mse: 39678700.0000\n",
            "Epoch 113/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3086.9404 - mae: 3086.9404 - mse: 36445140.0000 - val_loss: 3313.8167 - val_mae: 3313.8167 - val_mse: 36437812.0000\n",
            "Epoch 114/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2996.5183 - mae: 2996.5183 - mse: 36212204.0000 - val_loss: 3740.4688 - val_mae: 3740.4688 - val_mse: 38436232.0000\n",
            "Epoch 115/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3123.2754 - mae: 3123.2754 - mse: 36011152.0000 - val_loss: 3051.5432 - val_mae: 3051.5432 - val_mse: 35992408.0000\n",
            "Epoch 116/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3024.8179 - mae: 3024.8179 - mse: 36590524.0000 - val_loss: 2899.8240 - val_mae: 2899.8240 - val_mse: 34004924.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 117/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3016.0972 - mae: 3016.0972 - mse: 36209192.0000 - val_loss: 3051.8845 - val_mae: 3051.8845 - val_mse: 36254852.0000\n",
            "Epoch 118/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3025.4719 - mae: 3025.4722 - mse: 36288404.0000 - val_loss: 2912.4287 - val_mae: 2912.4287 - val_mse: 34798892.0000\n",
            "Epoch 119/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3004.7297 - mae: 3004.7297 - mse: 36562920.0000 - val_loss: 3023.4495 - val_mae: 3023.4495 - val_mse: 34796752.0000\n",
            "Epoch 120/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3000.5151 - mae: 3000.5151 - mse: 35377100.0000 - val_loss: 2883.6448 - val_mae: 2883.6448 - val_mse: 38082036.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 121/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2991.4495 - mae: 2991.4495 - mse: 36214792.0000 - val_loss: 2971.4116 - val_mae: 2971.4116 - val_mse: 35218268.0000\n",
            "Epoch 122/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2987.3894 - mae: 2987.3894 - mse: 36327188.0000 - val_loss: 2921.8989 - val_mae: 2921.8989 - val_mse: 34147200.0000\n",
            "Epoch 123/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2910.7629 - mae: 2910.7629 - mse: 35398956.0000 - val_loss: 3184.7837 - val_mae: 3184.7837 - val_mse: 33788444.0000\n",
            "Epoch 124/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2968.7236 - mae: 2968.7236 - mse: 35295780.0000 - val_loss: 2922.3428 - val_mae: 2922.3428 - val_mse: 33583220.0000\n",
            "Epoch 125/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2968.5818 - mae: 2968.5818 - mse: 35696168.0000 - val_loss: 3112.1753 - val_mae: 3112.1753 - val_mse: 34023128.0000\n",
            "Epoch 126/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2911.2532 - mae: 2911.2532 - mse: 34897468.0000 - val_loss: 3089.8643 - val_mae: 3089.8643 - val_mse: 34868176.0000\n",
            "Epoch 127/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2894.6765 - mae: 2894.6765 - mse: 34509820.0000 - val_loss: 2817.7158 - val_mae: 2817.7158 - val_mse: 33212588.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 128/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2973.3665 - mae: 2973.3665 - mse: 35405944.0000 - val_loss: 2742.7534 - val_mae: 2742.7534 - val_mse: 33464056.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 129/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2932.2751 - mae: 2932.2751 - mse: 35379320.0000 - val_loss: 2763.8953 - val_mae: 2763.8953 - val_mse: 33660336.0000\n",
            "Epoch 130/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2923.6921 - mae: 2923.6919 - mse: 35101108.0000 - val_loss: 3131.9526 - val_mae: 3131.9526 - val_mse: 33954844.0000\n",
            "Epoch 131/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2930.9014 - mae: 2930.9014 - mse: 34087548.0000 - val_loss: 2796.8113 - val_mae: 2796.8113 - val_mse: 32636742.0000\n",
            "Epoch 132/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2881.1340 - mae: 2881.1340 - mse: 34687620.0000 - val_loss: 2967.3254 - val_mae: 2967.3254 - val_mse: 33026726.0000\n",
            "Epoch 133/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2895.9014 - mae: 2895.9014 - mse: 35067776.0000 - val_loss: 3122.0535 - val_mae: 3122.0535 - val_mse: 33875088.0000\n",
            "Epoch 134/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2873.2407 - mae: 2873.2407 - mse: 34283260.0000 - val_loss: 2806.8142 - val_mae: 2806.8142 - val_mse: 33874288.0000\n",
            "Epoch 135/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2910.6980 - mae: 2910.6980 - mse: 34957820.0000 - val_loss: 2734.2351 - val_mae: 2734.2351 - val_mse: 32137858.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 136/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2855.3210 - mae: 2855.3210 - mse: 33722176.0000 - val_loss: 2841.6858 - val_mae: 2841.6858 - val_mse: 32854478.0000\n",
            "Epoch 137/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2843.9744 - mae: 2843.9744 - mse: 33737820.0000 - val_loss: 2719.2366 - val_mae: 2719.2366 - val_mse: 32655254.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 138/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2865.7302 - mae: 2865.7302 - mse: 34381548.0000 - val_loss: 2764.3657 - val_mae: 2764.3657 - val_mse: 32343854.0000\n",
            "Epoch 139/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2878.2600 - mae: 2878.2600 - mse: 34590548.0000 - val_loss: 2766.5103 - val_mae: 2766.5103 - val_mse: 32219992.0000\n",
            "Epoch 140/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2886.3931 - mae: 2886.3931 - mse: 35024340.0000 - val_loss: 2844.8970 - val_mae: 2844.8970 - val_mse: 33359714.0000\n",
            "Epoch 141/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2844.7317 - mae: 2844.7317 - mse: 34228404.0000 - val_loss: 2788.9185 - val_mae: 2788.9185 - val_mse: 31831076.0000\n",
            "Epoch 142/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2803.1162 - mae: 2803.1162 - mse: 34027100.0000 - val_loss: 3182.2056 - val_mae: 3182.2056 - val_mse: 33521424.0000\n",
            "Epoch 143/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2820.6165 - mae: 2820.6165 - mse: 33857344.0000 - val_loss: 2689.0830 - val_mae: 2689.0830 - val_mse: 31751170.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 144/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2764.5032 - mae: 2764.5032 - mse: 32893530.0000 - val_loss: 2852.1577 - val_mae: 2852.1577 - val_mse: 34679344.0000\n",
            "Epoch 145/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2803.9419 - mae: 2803.9419 - mse: 33332032.0000 - val_loss: 3110.7620 - val_mae: 3110.7620 - val_mse: 33163472.0000\n",
            "Epoch 146/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2776.2803 - mae: 2776.2803 - mse: 33211176.0000 - val_loss: 3468.1294 - val_mae: 3468.1296 - val_mse: 34829244.0000\n",
            "Epoch 147/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2795.9922 - mae: 2795.9922 - mse: 33449812.0000 - val_loss: 3070.6104 - val_mae: 3070.6104 - val_mse: 33139074.0000\n",
            "Epoch 148/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2758.0969 - mae: 2758.0969 - mse: 32409940.0000 - val_loss: 2598.5195 - val_mae: 2598.5195 - val_mse: 32754404.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 149/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2782.8313 - mae: 2782.8313 - mse: 33282972.0000 - val_loss: 2822.2859 - val_mae: 2822.2859 - val_mse: 33061922.0000\n",
            "Epoch 150/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2728.6943 - mae: 2728.6943 - mse: 33509070.0000 - val_loss: 2744.8225 - val_mae: 2744.8225 - val_mse: 31653634.0000\n",
            "Epoch 151/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2745.3242 - mae: 2745.3242 - mse: 32829456.0000 - val_loss: 2722.0164 - val_mae: 2722.0164 - val_mse: 33556836.0000\n",
            "Epoch 152/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2724.1819 - mae: 2724.1819 - mse: 32618212.0000 - val_loss: 2576.5583 - val_mae: 2576.5583 - val_mse: 31311754.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 153/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2782.8025 - mae: 2782.8025 - mse: 32511338.0000 - val_loss: 2629.2903 - val_mae: 2629.2903 - val_mse: 31733590.0000\n",
            "Epoch 154/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2737.5010 - mae: 2737.5010 - mse: 32865502.0000 - val_loss: 2571.0940 - val_mae: 2571.0940 - val_mse: 31278280.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 155/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2745.8057 - mae: 2745.8057 - mse: 33737944.0000 - val_loss: 2599.1313 - val_mae: 2599.1313 - val_mse: 32404854.0000\n",
            "Epoch 156/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2674.9644 - mae: 2674.9644 - mse: 32638062.0000 - val_loss: 2655.6963 - val_mae: 2655.6963 - val_mse: 33043860.0000\n",
            "Epoch 157/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2741.7795 - mae: 2741.7795 - mse: 32310020.0000 - val_loss: 2946.6636 - val_mae: 2946.6636 - val_mse: 32479764.0000\n",
            "Epoch 158/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2742.7629 - mae: 2742.7629 - mse: 33111764.0000 - val_loss: 2765.3240 - val_mae: 2765.3240 - val_mse: 32046224.0000\n",
            "Epoch 159/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2692.3809 - mae: 2692.3809 - mse: 33101114.0000 - val_loss: 2862.4333 - val_mae: 2862.4333 - val_mse: 32327372.0000\n",
            "Epoch 160/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2713.1714 - mae: 2713.1714 - mse: 32681414.0000 - val_loss: 2528.2366 - val_mae: 2528.2366 - val_mse: 31298540.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 161/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2714.4500 - mae: 2714.4500 - mse: 33073782.0000 - val_loss: 2588.4463 - val_mae: 2588.4463 - val_mse: 31668074.0000\n",
            "Epoch 162/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2667.2102 - mae: 2667.2102 - mse: 32637962.0000 - val_loss: 3135.5422 - val_mae: 3135.5422 - val_mse: 33344940.0000\n",
            "Epoch 163/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2723.0159 - mae: 2723.0159 - mse: 32444030.0000 - val_loss: 2643.1682 - val_mae: 2643.1682 - val_mse: 30346716.0000\n",
            "Epoch 164/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2668.8066 - mae: 2668.8066 - mse: 32084626.0000 - val_loss: 3122.3677 - val_mae: 3122.3677 - val_mse: 33644744.0000\n",
            "Epoch 165/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2619.5422 - mae: 2619.5422 - mse: 31310980.0000 - val_loss: 2818.5566 - val_mae: 2818.5566 - val_mse: 31113986.0000\n",
            "Epoch 166/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2670.3306 - mae: 2670.3306 - mse: 32152454.0000 - val_loss: 2763.3838 - val_mae: 2763.3838 - val_mse: 31619632.0000\n",
            "Epoch 167/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2688.3298 - mae: 2688.3298 - mse: 32364542.0000 - val_loss: 2687.1670 - val_mae: 2687.1670 - val_mse: 31175614.0000\n",
            "Epoch 168/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2674.1013 - mae: 2674.1013 - mse: 31906064.0000 - val_loss: 2616.7742 - val_mae: 2616.7742 - val_mse: 29859068.0000\n",
            "Epoch 169/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2665.3748 - mae: 2665.3748 - mse: 32482466.0000 - val_loss: 2545.0801 - val_mae: 2545.0801 - val_mse: 30545078.0000\n",
            "Epoch 170/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2628.2810 - mae: 2628.2810 - mse: 31927100.0000 - val_loss: 2658.4431 - val_mae: 2658.4431 - val_mse: 31566470.0000\n",
            "Epoch 171/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2649.7861 - mae: 2649.7861 - mse: 31801790.0000 - val_loss: 2537.2615 - val_mae: 2537.2615 - val_mse: 31894532.0000\n",
            "Epoch 172/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2629.6963 - mae: 2629.6963 - mse: 31753628.0000 - val_loss: 2768.0308 - val_mae: 2768.0308 - val_mse: 31407774.0000\n",
            "Epoch 173/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2593.3762 - mae: 2593.3762 - mse: 31156746.0000 - val_loss: 2515.2212 - val_mae: 2515.2212 - val_mse: 30038178.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 174/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2581.7063 - mae: 2581.7063 - mse: 31012750.0000 - val_loss: 2860.9341 - val_mae: 2860.9341 - val_mse: 31230730.0000\n",
            "Epoch 175/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2622.0059 - mae: 2622.0059 - mse: 31762508.0000 - val_loss: 2534.7334 - val_mae: 2534.7334 - val_mse: 29895342.0000\n",
            "Epoch 176/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2572.5754 - mae: 2572.5754 - mse: 30134874.0000 - val_loss: 2762.6101 - val_mae: 2762.6101 - val_mse: 30675506.0000\n",
            "Epoch 177/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2606.8035 - mae: 2606.8035 - mse: 31341190.0000 - val_loss: 3460.9819 - val_mae: 3460.9819 - val_mse: 36569408.0000\n",
            "Epoch 178/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2604.3613 - mae: 2604.3613 - mse: 31698168.0000 - val_loss: 2590.8286 - val_mae: 2590.8286 - val_mse: 29652124.0000\n",
            "Epoch 179/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2628.2512 - mae: 2628.2512 - mse: 31005042.0000 - val_loss: 2601.6011 - val_mae: 2601.6011 - val_mse: 31096932.0000\n",
            "Epoch 180/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2573.4202 - mae: 2573.4202 - mse: 30856206.0000 - val_loss: 2550.2458 - val_mae: 2550.2458 - val_mse: 30385336.0000\n",
            "Epoch 181/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2598.0701 - mae: 2598.0701 - mse: 31147906.0000 - val_loss: 2550.3760 - val_mae: 2550.3760 - val_mse: 30479956.0000\n",
            "Epoch 182/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2572.7961 - mae: 2572.7961 - mse: 30305156.0000 - val_loss: 2473.5652 - val_mae: 2473.5652 - val_mse: 30564026.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 183/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2599.7837 - mae: 2599.7837 - mse: 30999280.0000 - val_loss: 2806.6169 - val_mae: 2806.6169 - val_mse: 30044814.0000\n",
            "Epoch 184/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2584.1135 - mae: 2584.1135 - mse: 30511546.0000 - val_loss: 2573.1292 - val_mae: 2573.1292 - val_mse: 30882766.0000\n",
            "Epoch 185/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2579.8853 - mae: 2579.8853 - mse: 30706674.0000 - val_loss: 2560.6279 - val_mae: 2560.6279 - val_mse: 29046330.0000\n",
            "Epoch 186/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2547.8672 - mae: 2547.8672 - mse: 30979586.0000 - val_loss: 2449.2712 - val_mae: 2449.2712 - val_mse: 29992940.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 187/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2587.3831 - mae: 2587.3831 - mse: 31115388.0000 - val_loss: 2557.4453 - val_mae: 2557.4453 - val_mse: 29856636.0000\n",
            "Epoch 188/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2587.0564 - mae: 2587.0564 - mse: 31026384.0000 - val_loss: 2552.0415 - val_mae: 2552.0415 - val_mse: 29283106.0000\n",
            "Epoch 189/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2548.8674 - mae: 2548.8674 - mse: 30610420.0000 - val_loss: 2483.7676 - val_mae: 2483.7676 - val_mse: 29586642.0000\n",
            "Epoch 190/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2545.7334 - mae: 2545.7334 - mse: 30145172.0000 - val_loss: 2405.8411 - val_mae: 2405.8411 - val_mse: 29125356.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 191/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2526.4153 - mae: 2526.4153 - mse: 30389404.0000 - val_loss: 2888.3828 - val_mae: 2888.3828 - val_mse: 30575510.0000\n",
            "Epoch 192/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2592.0093 - mae: 2592.0093 - mse: 30225956.0000 - val_loss: 2436.7178 - val_mae: 2436.7178 - val_mse: 29835174.0000\n",
            "Epoch 193/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2510.5464 - mae: 2510.5464 - mse: 30148622.0000 - val_loss: 2906.4819 - val_mae: 2906.4819 - val_mse: 30680420.0000\n",
            "Epoch 194/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2549.2207 - mae: 2549.2207 - mse: 30225538.0000 - val_loss: 2448.7446 - val_mae: 2448.7446 - val_mse: 29010120.0000\n",
            "Epoch 195/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2542.7920 - mae: 2542.7920 - mse: 30273702.0000 - val_loss: 2514.8403 - val_mae: 2514.8403 - val_mse: 28506462.0000\n",
            "Epoch 196/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2538.5254 - mae: 2538.5254 - mse: 30306626.0000 - val_loss: 2548.6118 - val_mae: 2548.6118 - val_mse: 29961910.0000\n",
            "Epoch 197/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2512.3350 - mae: 2512.3350 - mse: 30116498.0000 - val_loss: 2574.3086 - val_mae: 2574.3086 - val_mse: 29529730.0000\n",
            "Epoch 198/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2545.9028 - mae: 2545.9028 - mse: 30749506.0000 - val_loss: 2446.2852 - val_mae: 2446.2852 - val_mse: 28634500.0000\n",
            "Epoch 199/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2474.9812 - mae: 2474.9812 - mse: 29556488.0000 - val_loss: 2593.3428 - val_mae: 2593.3428 - val_mse: 28530290.0000\n",
            "Epoch 200/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2522.7056 - mae: 2522.7056 - mse: 29534210.0000 - val_loss: 2717.8604 - val_mae: 2717.8604 - val_mse: 29626114.0000\n",
            "Epoch 201/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2468.7556 - mae: 2468.7556 - mse: 29599560.0000 - val_loss: 2741.8818 - val_mae: 2741.8818 - val_mse: 29596878.0000\n",
            "Epoch 202/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2535.5420 - mae: 2535.5420 - mse: 29869466.0000 - val_loss: 2463.5764 - val_mae: 2463.5764 - val_mse: 27896122.0000\n",
            "Epoch 203/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2470.1438 - mae: 2470.1438 - mse: 29394740.0000 - val_loss: 2459.4854 - val_mae: 2459.4854 - val_mse: 28781692.0000\n",
            "Epoch 204/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2511.9536 - mae: 2511.9536 - mse: 29510068.0000 - val_loss: 2719.0251 - val_mae: 2719.0251 - val_mse: 30610222.0000\n",
            "Epoch 205/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2494.1726 - mae: 2494.1726 - mse: 29590720.0000 - val_loss: 2519.2922 - val_mae: 2519.2922 - val_mse: 29093318.0000\n",
            "Epoch 206/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2508.5317 - mae: 2508.5317 - mse: 29875172.0000 - val_loss: 2369.8391 - val_mae: 2369.8391 - val_mse: 28062900.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 207/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2476.1233 - mae: 2476.1233 - mse: 29004364.0000 - val_loss: 2470.0193 - val_mae: 2470.0193 - val_mse: 28411704.0000\n",
            "Epoch 208/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2462.6841 - mae: 2462.6841 - mse: 28750004.0000 - val_loss: 2517.3687 - val_mae: 2517.3687 - val_mse: 27710186.0000\n",
            "Epoch 209/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2453.7886 - mae: 2453.7886 - mse: 28731592.0000 - val_loss: 2498.3555 - val_mae: 2498.3555 - val_mse: 30463578.0000\n",
            "Epoch 210/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2491.8164 - mae: 2491.8164 - mse: 29073082.0000 - val_loss: 2490.5779 - val_mae: 2490.5779 - val_mse: 27278392.0000\n",
            "Epoch 211/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2427.7742 - mae: 2427.7742 - mse: 28764420.0000 - val_loss: 2566.4697 - val_mae: 2566.4697 - val_mse: 29164474.0000\n",
            "Epoch 212/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2494.9375 - mae: 2494.9375 - mse: 29084536.0000 - val_loss: 2335.7856 - val_mae: 2335.7856 - val_mse: 27888824.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 213/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2439.3345 - mae: 2439.3345 - mse: 28432810.0000 - val_loss: 2443.9756 - val_mae: 2443.9756 - val_mse: 28312316.0000\n",
            "Epoch 214/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2455.3625 - mae: 2455.3625 - mse: 29251820.0000 - val_loss: 2573.2039 - val_mae: 2573.2039 - val_mse: 28575254.0000\n",
            "Epoch 215/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2410.2944 - mae: 2410.2944 - mse: 28645064.0000 - val_loss: 2978.9883 - val_mae: 2978.9883 - val_mse: 30139356.0000\n",
            "Epoch 216/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2468.3779 - mae: 2468.3779 - mse: 28994204.0000 - val_loss: 2622.5352 - val_mae: 2622.5352 - val_mse: 27496684.0000\n",
            "Epoch 217/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2428.2476 - mae: 2428.2476 - mse: 28851302.0000 - val_loss: 2560.7607 - val_mae: 2560.7607 - val_mse: 28452490.0000\n",
            "Epoch 218/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2421.9727 - mae: 2421.9727 - mse: 28351512.0000 - val_loss: 2435.7742 - val_mae: 2435.7742 - val_mse: 27931112.0000\n",
            "Epoch 219/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2396.6218 - mae: 2396.6218 - mse: 28477412.0000 - val_loss: 2331.9690 - val_mae: 2331.9690 - val_mse: 27276930.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 220/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2417.1772 - mae: 2417.1772 - mse: 27806890.0000 - val_loss: 2420.2307 - val_mae: 2420.2307 - val_mse: 26567108.0000\n",
            "Epoch 221/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2369.3413 - mae: 2369.3413 - mse: 27952790.0000 - val_loss: 2363.0703 - val_mae: 2363.0703 - val_mse: 26447352.0000\n",
            "Epoch 222/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2394.6494 - mae: 2394.6494 - mse: 28340802.0000 - val_loss: 2458.0059 - val_mae: 2458.0059 - val_mse: 26506340.0000\n",
            "Epoch 223/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2415.1619 - mae: 2415.1619 - mse: 28084164.0000 - val_loss: 2569.2302 - val_mae: 2569.2302 - val_mse: 27709916.0000\n",
            "Epoch 224/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2476.6672 - mae: 2476.6672 - mse: 28663358.0000 - val_loss: 2587.9048 - val_mae: 2587.9048 - val_mse: 27638086.0000\n",
            "Epoch 225/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2384.2732 - mae: 2384.2732 - mse: 27841540.0000 - val_loss: 2867.0564 - val_mae: 2867.0564 - val_mse: 29981840.0000\n",
            "Epoch 226/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2410.6514 - mae: 2410.6514 - mse: 28406806.0000 - val_loss: 2253.8186 - val_mae: 2253.8186 - val_mse: 26672794.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 227/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2383.2502 - mae: 2383.2502 - mse: 28063442.0000 - val_loss: 2883.5842 - val_mae: 2883.5842 - val_mse: 28967280.0000\n",
            "Epoch 228/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2382.1477 - mae: 2382.1477 - mse: 28014158.0000 - val_loss: 2619.7639 - val_mae: 2619.7639 - val_mse: 28049628.0000\n",
            "Epoch 229/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2367.8003 - mae: 2367.8003 - mse: 27720230.0000 - val_loss: 2208.0862 - val_mae: 2208.0862 - val_mse: 27369230.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 230/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2361.2720 - mae: 2361.2720 - mse: 27737782.0000 - val_loss: 2233.6836 - val_mae: 2233.6836 - val_mse: 26348756.0000\n",
            "Epoch 231/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2349.6375 - mae: 2349.6375 - mse: 27538958.0000 - val_loss: 3086.5010 - val_mae: 3086.5010 - val_mse: 30605994.0000\n",
            "Epoch 232/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2364.4988 - mae: 2364.4988 - mse: 27134302.0000 - val_loss: 2224.8779 - val_mae: 2224.8779 - val_mse: 26461440.0000\n",
            "Epoch 233/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2350.1204 - mae: 2350.1204 - mse: 27483522.0000 - val_loss: 2297.3635 - val_mae: 2297.3635 - val_mse: 25835372.0000\n",
            "Epoch 234/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2328.4563 - mae: 2328.4563 - mse: 27128428.0000 - val_loss: 2569.2708 - val_mae: 2569.2708 - val_mse: 26936402.0000\n",
            "Epoch 235/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2372.7620 - mae: 2372.7620 - mse: 27482646.0000 - val_loss: 2282.2776 - val_mae: 2282.2776 - val_mse: 25617322.0000\n",
            "Epoch 236/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2334.2883 - mae: 2334.2883 - mse: 26688254.0000 - val_loss: 2578.4871 - val_mae: 2578.4871 - val_mse: 26848270.0000\n",
            "Epoch 237/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2337.6072 - mae: 2337.6072 - mse: 27035330.0000 - val_loss: 2219.7495 - val_mae: 2219.7495 - val_mse: 25560686.0000\n",
            "Epoch 238/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2312.6812 - mae: 2312.6812 - mse: 26557674.0000 - val_loss: 2628.7964 - val_mae: 2628.7964 - val_mse: 25794760.0000\n",
            "Epoch 239/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2321.5408 - mae: 2321.5408 - mse: 26657158.0000 - val_loss: 2649.4390 - val_mae: 2649.4390 - val_mse: 27138698.0000\n",
            "Epoch 240/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2314.7312 - mae: 2314.7312 - mse: 26379744.0000 - val_loss: 2179.1475 - val_mae: 2179.1475 - val_mse: 26342960.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 241/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2344.7717 - mae: 2344.7717 - mse: 27150904.0000 - val_loss: 2262.9448 - val_mae: 2262.9448 - val_mse: 25174502.0000\n",
            "Epoch 242/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2304.4868 - mae: 2304.4868 - mse: 26411094.0000 - val_loss: 2263.2971 - val_mae: 2263.2971 - val_mse: 25155014.0000\n",
            "Epoch 243/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2311.6396 - mae: 2311.6396 - mse: 26352136.0000 - val_loss: 2180.9399 - val_mae: 2180.9399 - val_mse: 25327618.0000\n",
            "Epoch 244/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2272.9009 - mae: 2272.9009 - mse: 25982278.0000 - val_loss: 2264.9521 - val_mae: 2264.9521 - val_mse: 25610110.0000\n",
            "Epoch 245/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2293.2117 - mae: 2293.2117 - mse: 26362208.0000 - val_loss: 2370.0635 - val_mae: 2370.0635 - val_mse: 26072160.0000\n",
            "Epoch 246/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2275.7275 - mae: 2275.7275 - mse: 26150704.0000 - val_loss: 2186.4961 - val_mae: 2186.4961 - val_mse: 25984632.0000\n",
            "Epoch 247/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2285.4941 - mae: 2285.4941 - mse: 26270306.0000 - val_loss: 2732.9995 - val_mae: 2732.9995 - val_mse: 26410016.0000\n",
            "Epoch 248/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2273.4307 - mae: 2273.4307 - mse: 26464784.0000 - val_loss: 2400.9460 - val_mae: 2400.9460 - val_mse: 25983390.0000\n",
            "Epoch 249/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2302.9719 - mae: 2302.9719 - mse: 26276562.0000 - val_loss: 2244.8796 - val_mae: 2244.8796 - val_mse: 25514814.0000\n",
            "Epoch 250/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2255.9380 - mae: 2255.9380 - mse: 25498624.0000 - val_loss: 2447.2893 - val_mae: 2447.2893 - val_mse: 25200068.0000\n",
            "Epoch 251/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2265.4583 - mae: 2265.4583 - mse: 25696434.0000 - val_loss: 2315.4451 - val_mae: 2315.4451 - val_mse: 25498730.0000\n",
            "Epoch 252/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2262.2319 - mae: 2262.2319 - mse: 25650322.0000 - val_loss: 2707.1870 - val_mae: 2707.1870 - val_mse: 27566380.0000\n",
            "Epoch 253/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2270.2671 - mae: 2270.2671 - mse: 26018132.0000 - val_loss: 2134.9536 - val_mae: 2134.9536 - val_mse: 24640230.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 254/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2239.2161 - mae: 2239.2161 - mse: 25771914.0000 - val_loss: 2274.2412 - val_mae: 2274.2412 - val_mse: 24955284.0000\n",
            "Epoch 255/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2241.0901 - mae: 2241.0901 - mse: 25222018.0000 - val_loss: 2293.6448 - val_mae: 2293.6448 - val_mse: 24479748.0000\n",
            "Epoch 256/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2226.1057 - mae: 2226.1057 - mse: 25531528.0000 - val_loss: 2398.8818 - val_mae: 2398.8818 - val_mse: 24592738.0000\n",
            "Epoch 257/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2269.2988 - mae: 2269.2988 - mse: 25062582.0000 - val_loss: 2203.7063 - val_mae: 2203.7063 - val_mse: 24847466.0000\n",
            "Epoch 258/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2205.5488 - mae: 2205.5488 - mse: 24702820.0000 - val_loss: 2693.1245 - val_mae: 2693.1245 - val_mse: 27429868.0000\n",
            "Epoch 259/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2237.5703 - mae: 2237.5703 - mse: 25275838.0000 - val_loss: 2093.9045 - val_mae: 2093.9045 - val_mse: 24582290.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 260/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2241.2234 - mae: 2241.2234 - mse: 25426744.0000 - val_loss: 2189.7969 - val_mae: 2189.7969 - val_mse: 24253930.0000\n",
            "Epoch 261/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2203.8467 - mae: 2203.8467 - mse: 24977802.0000 - val_loss: 2461.6179 - val_mae: 2461.6179 - val_mse: 24446294.0000\n",
            "Epoch 262/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2194.9353 - mae: 2194.9353 - mse: 24663496.0000 - val_loss: 2136.8301 - val_mae: 2136.8301 - val_mse: 24881504.0000\n",
            "Epoch 263/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2220.6982 - mae: 2220.6982 - mse: 24623580.0000 - val_loss: 2131.1323 - val_mae: 2131.1323 - val_mse: 23704426.0000\n",
            "Epoch 264/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2202.8308 - mae: 2202.8308 - mse: 24481586.0000 - val_loss: 2299.4333 - val_mae: 2299.4333 - val_mse: 24828272.0000\n",
            "Epoch 265/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2185.2202 - mae: 2185.2202 - mse: 24427168.0000 - val_loss: 2840.5547 - val_mae: 2840.5547 - val_mse: 26349510.0000\n",
            "Epoch 266/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2200.9968 - mae: 2200.9968 - mse: 24755884.0000 - val_loss: 2137.2629 - val_mae: 2137.2629 - val_mse: 23168698.0000\n",
            "Epoch 267/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2166.5706 - mae: 2166.5706 - mse: 24200172.0000 - val_loss: 2419.4546 - val_mae: 2419.4546 - val_mse: 23303692.0000\n",
            "Epoch 268/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2148.6055 - mae: 2148.6055 - mse: 24028366.0000 - val_loss: 2047.6519 - val_mae: 2047.6519 - val_mse: 23383296.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 269/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2163.1365 - mae: 2163.1365 - mse: 23994664.0000 - val_loss: 2628.7424 - val_mae: 2628.7424 - val_mse: 25575034.0000\n",
            "Epoch 270/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2166.3396 - mae: 2166.3396 - mse: 24025678.0000 - val_loss: 2129.4172 - val_mae: 2129.4172 - val_mse: 22842966.0000\n",
            "Epoch 271/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2164.9653 - mae: 2164.9653 - mse: 24195596.0000 - val_loss: 2152.2390 - val_mae: 2152.2390 - val_mse: 23785662.0000\n",
            "Epoch 272/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2154.9563 - mae: 2154.9563 - mse: 23883468.0000 - val_loss: 2082.3127 - val_mae: 2082.3127 - val_mse: 23465524.0000\n",
            "Epoch 273/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2159.7310 - mae: 2159.7310 - mse: 23870488.0000 - val_loss: 2205.6956 - val_mae: 2205.6956 - val_mse: 24103458.0000\n",
            "Epoch 274/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2150.6272 - mae: 2150.6272 - mse: 23618300.0000 - val_loss: 2216.8562 - val_mae: 2216.8562 - val_mse: 23783366.0000\n",
            "Epoch 275/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2135.9912 - mae: 2135.9912 - mse: 24163776.0000 - val_loss: 2758.0928 - val_mae: 2758.0928 - val_mse: 25094704.0000\n",
            "Epoch 276/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2129.0349 - mae: 2129.0349 - mse: 23959362.0000 - val_loss: 2309.8354 - val_mae: 2309.8354 - val_mse: 24272714.0000\n",
            "Epoch 277/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2164.2407 - mae: 2164.2407 - mse: 23723206.0000 - val_loss: 2147.0627 - val_mae: 2147.0627 - val_mse: 23542274.0000\n",
            "Epoch 278/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2174.8301 - mae: 2174.8301 - mse: 23589032.0000 - val_loss: 2220.3772 - val_mae: 2220.3772 - val_mse: 22886688.0000\n",
            "Epoch 279/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2133.8611 - mae: 2133.8611 - mse: 23257182.0000 - val_loss: 2146.7603 - val_mae: 2146.7603 - val_mse: 23548924.0000\n",
            "Epoch 280/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2113.7407 - mae: 2113.7407 - mse: 23356918.0000 - val_loss: 2013.6814 - val_mae: 2013.6814 - val_mse: 22459126.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 281/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2091.9421 - mae: 2091.9421 - mse: 23178752.0000 - val_loss: 2084.2966 - val_mae: 2084.2966 - val_mse: 23185290.0000\n",
            "Epoch 282/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2123.9653 - mae: 2123.9653 - mse: 23453170.0000 - val_loss: 2375.3672 - val_mae: 2375.3672 - val_mse: 24426992.0000\n",
            "Epoch 283/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2099.2908 - mae: 2099.2908 - mse: 23124524.0000 - val_loss: 2447.0132 - val_mae: 2447.0132 - val_mse: 25321178.0000\n",
            "Epoch 284/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2079.4080 - mae: 2079.4080 - mse: 22877880.0000 - val_loss: 2026.7766 - val_mae: 2026.7766 - val_mse: 22594248.0000\n",
            "Epoch 285/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2125.2251 - mae: 2125.2251 - mse: 23209594.0000 - val_loss: 2297.0120 - val_mae: 2297.0120 - val_mse: 22278350.0000\n",
            "Epoch 286/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2087.0398 - mae: 2087.0398 - mse: 22364638.0000 - val_loss: 2005.5110 - val_mae: 2005.5110 - val_mse: 22263988.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 287/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2089.8477 - mae: 2089.8477 - mse: 22718596.0000 - val_loss: 2133.3333 - val_mae: 2133.3333 - val_mse: 21855600.0000\n",
            "Epoch 288/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2079.0828 - mae: 2079.0828 - mse: 22719002.0000 - val_loss: 2220.7224 - val_mae: 2220.7224 - val_mse: 21954730.0000\n",
            "Epoch 289/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2093.9915 - mae: 2093.9915 - mse: 22758766.0000 - val_loss: 2166.4265 - val_mae: 2166.4265 - val_mse: 23045896.0000\n",
            "Epoch 290/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2046.6866 - mae: 2046.6866 - mse: 22222758.0000 - val_loss: 2398.1892 - val_mae: 2398.1892 - val_mse: 22317776.0000\n",
            "Epoch 291/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2070.5696 - mae: 2070.5696 - mse: 22400770.0000 - val_loss: 2118.4521 - val_mae: 2118.4521 - val_mse: 21643008.0000\n",
            "Epoch 292/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2085.9314 - mae: 2085.9314 - mse: 22685036.0000 - val_loss: 2044.0076 - val_mae: 2044.0076 - val_mse: 22697096.0000\n",
            "Epoch 293/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2091.7207 - mae: 2091.7207 - mse: 22591182.0000 - val_loss: 2007.2933 - val_mae: 2007.2933 - val_mse: 21870632.0000\n",
            "Epoch 294/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2044.4192 - mae: 2044.4192 - mse: 22397626.0000 - val_loss: 2178.3479 - val_mae: 2178.3479 - val_mse: 21487642.0000\n",
            "Epoch 295/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2053.2351 - mae: 2053.2351 - mse: 22516200.0000 - val_loss: 1992.3666 - val_mae: 1992.3666 - val_mse: 22045232.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 296/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2015.4479 - mae: 2015.4479 - mse: 22372534.0000 - val_loss: 2340.9907 - val_mae: 2340.9907 - val_mse: 21706398.0000\n",
            "Epoch 297/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2086.3445 - mae: 2086.3445 - mse: 22483172.0000 - val_loss: 2356.8738 - val_mae: 2356.8738 - val_mse: 23822662.0000\n",
            "Epoch 298/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2078.4519 - mae: 2078.4519 - mse: 22553148.0000 - val_loss: 1986.0463 - val_mae: 1986.0463 - val_mse: 21722280.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 299/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2066.6960 - mae: 2066.6960 - mse: 22235262.0000 - val_loss: 2253.3926 - val_mae: 2253.3926 - val_mse: 24278018.0000\n",
            "Epoch 300/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2059.4507 - mae: 2059.4507 - mse: 22454710.0000 - val_loss: 2071.4915 - val_mae: 2071.4915 - val_mse: 22187622.0000\n",
            "Epoch 301/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2032.9910 - mae: 2032.9910 - mse: 22212390.0000 - val_loss: 2203.6587 - val_mae: 2203.6587 - val_mse: 21172470.0000\n",
            "Epoch 302/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2002.1282 - mae: 2002.1282 - mse: 22041300.0000 - val_loss: 2317.1018 - val_mae: 2317.1018 - val_mse: 21505208.0000\n",
            "Epoch 303/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2058.2502 - mae: 2058.2502 - mse: 22575736.0000 - val_loss: 2368.9124 - val_mae: 2368.9124 - val_mse: 21310244.0000\n",
            "Epoch 304/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2020.0796 - mae: 2020.0796 - mse: 21831050.0000 - val_loss: 2028.3024 - val_mae: 2028.3024 - val_mse: 21984340.0000\n",
            "Epoch 305/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2082.5254 - mae: 2082.5254 - mse: 22240818.0000 - val_loss: 2037.9183 - val_mae: 2037.9183 - val_mse: 22400874.0000\n",
            "Epoch 306/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2021.3326 - mae: 2021.3326 - mse: 21841322.0000 - val_loss: 2047.9285 - val_mae: 2047.9285 - val_mse: 21288488.0000\n",
            "Epoch 307/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2045.3721 - mae: 2045.3721 - mse: 22125506.0000 - val_loss: 2108.0859 - val_mae: 2108.0859 - val_mse: 22545774.0000\n",
            "Epoch 308/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1981.4760 - mae: 1981.4760 - mse: 21605006.0000 - val_loss: 2170.2712 - val_mae: 2170.2712 - val_mse: 23811994.0000\n",
            "Epoch 309/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1999.4733 - mae: 1999.4733 - mse: 21415886.0000 - val_loss: 2664.5005 - val_mae: 2664.5005 - val_mse: 22151020.0000\n",
            "Epoch 310/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2006.7372 - mae: 2006.7372 - mse: 22003940.0000 - val_loss: 2160.5591 - val_mae: 2160.5591 - val_mse: 23662846.0000\n",
            "Epoch 311/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1977.7339 - mae: 1977.7339 - mse: 21520180.0000 - val_loss: 3203.1008 - val_mae: 3203.1008 - val_mse: 31639014.0000\n",
            "Epoch 312/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2050.4465 - mae: 2050.4465 - mse: 22152924.0000 - val_loss: 2020.6993 - val_mae: 2020.6993 - val_mse: 21709444.0000\n",
            "Epoch 313/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2043.4532 - mae: 2043.4532 - mse: 22232892.0000 - val_loss: 2213.6614 - val_mae: 2213.6614 - val_mse: 20556704.0000\n",
            "Epoch 314/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2035.0645 - mae: 2035.0645 - mse: 22056638.0000 - val_loss: 2222.5283 - val_mae: 2222.5283 - val_mse: 23232636.0000\n",
            "Epoch 315/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1972.8435 - mae: 1972.8435 - mse: 21593896.0000 - val_loss: 1960.1956 - val_mae: 1960.1956 - val_mse: 21943450.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 316/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2032.1151 - mae: 2032.1151 - mse: 21872850.0000 - val_loss: 2206.9915 - val_mae: 2206.9915 - val_mse: 23062322.0000\n",
            "Epoch 317/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1990.4152 - mae: 1990.4152 - mse: 21980616.0000 - val_loss: 2218.1096 - val_mae: 2218.1096 - val_mse: 22384626.0000\n",
            "Epoch 318/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2059.1863 - mae: 2059.1863 - mse: 22081870.0000 - val_loss: 2699.6489 - val_mae: 2699.6489 - val_mse: 23064128.0000\n",
            "Epoch 319/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1978.3070 - mae: 1978.3070 - mse: 20777474.0000 - val_loss: 2212.1555 - val_mae: 2212.1555 - val_mse: 20904412.0000\n",
            "Epoch 320/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1998.8207 - mae: 1998.8207 - mse: 21593018.0000 - val_loss: 1917.8733 - val_mae: 1917.8733 - val_mse: 21605122.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 321/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1967.9960 - mae: 1967.9960 - mse: 21368660.0000 - val_loss: 2053.6079 - val_mae: 2053.6079 - val_mse: 20684764.0000\n",
            "Epoch 322/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2001.2588 - mae: 2001.2588 - mse: 21477612.0000 - val_loss: 1973.6378 - val_mae: 1973.6378 - val_mse: 21483090.0000\n",
            "Epoch 323/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1990.6548 - mae: 1990.6548 - mse: 21588458.0000 - val_loss: 2692.0757 - val_mae: 2692.0757 - val_mse: 27868976.0000\n",
            "Epoch 324/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2055.9966 - mae: 2055.9966 - mse: 21884042.0000 - val_loss: 2271.8330 - val_mae: 2271.8330 - val_mse: 20516000.0000\n",
            "Epoch 325/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1972.6868 - mae: 1972.6868 - mse: 20919600.0000 - val_loss: 2298.8323 - val_mae: 2298.8323 - val_mse: 22775752.0000\n",
            "Epoch 326/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2022.8812 - mae: 2022.8812 - mse: 21937910.0000 - val_loss: 2081.1270 - val_mae: 2081.1270 - val_mse: 20825010.0000\n",
            "Epoch 327/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1970.4923 - mae: 1970.4923 - mse: 21512166.0000 - val_loss: 1953.6632 - val_mae: 1953.6632 - val_mse: 21667888.0000\n",
            "Epoch 328/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2003.6937 - mae: 2003.6937 - mse: 21674520.0000 - val_loss: 2073.2239 - val_mae: 2073.2239 - val_mse: 23153076.0000\n",
            "Epoch 329/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1966.5139 - mae: 1966.5139 - mse: 21586116.0000 - val_loss: 2464.8630 - val_mae: 2464.8630 - val_mse: 22071978.0000\n",
            "Epoch 330/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2040.5485 - mae: 2040.5485 - mse: 22052788.0000 - val_loss: 1892.7324 - val_mae: 1892.7324 - val_mse: 21230002.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 331/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1994.8947 - mae: 1994.8947 - mse: 21847872.0000 - val_loss: 2276.5664 - val_mae: 2276.5664 - val_mse: 22838066.0000\n",
            "Epoch 332/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1999.6416 - mae: 1999.6416 - mse: 21498486.0000 - val_loss: 2216.5049 - val_mae: 2216.5049 - val_mse: 23248382.0000\n",
            "Epoch 333/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2004.3987 - mae: 2004.3987 - mse: 21640120.0000 - val_loss: 1874.8363 - val_mae: 1874.8363 - val_mse: 20770644.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 334/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1973.0706 - mae: 1973.0706 - mse: 21263808.0000 - val_loss: 2557.9241 - val_mae: 2557.9241 - val_mse: 22754668.0000\n",
            "Epoch 335/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2021.0938 - mae: 2021.0938 - mse: 21879932.0000 - val_loss: 2055.3689 - val_mae: 2055.3689 - val_mse: 22052060.0000\n",
            "Epoch 336/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1940.1632 - mae: 1940.1632 - mse: 21058216.0000 - val_loss: 2217.4421 - val_mae: 2217.4421 - val_mse: 20343430.0000\n",
            "Epoch 337/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2003.8242 - mae: 2003.8242 - mse: 21819540.0000 - val_loss: 1995.5292 - val_mae: 1995.5292 - val_mse: 21537582.0000\n",
            "Epoch 338/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2001.5909 - mae: 2001.5909 - mse: 21351640.0000 - val_loss: 1958.5505 - val_mae: 1958.5505 - val_mse: 21724122.0000\n",
            "Epoch 339/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1982.3350 - mae: 1982.3350 - mse: 21675492.0000 - val_loss: 1931.5835 - val_mae: 1931.5835 - val_mse: 20964316.0000\n",
            "Epoch 340/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1996.1451 - mae: 1996.1451 - mse: 21461606.0000 - val_loss: 1901.8923 - val_mae: 1901.8923 - val_mse: 21123750.0000\n",
            "Epoch 341/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2000.6876 - mae: 2000.6876 - mse: 21744032.0000 - val_loss: 2133.7156 - val_mae: 2133.7156 - val_mse: 22796688.0000\n",
            "Epoch 342/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1937.7729 - mae: 1937.7729 - mse: 21383364.0000 - val_loss: 1949.4530 - val_mae: 1949.4530 - val_mse: 21111568.0000\n",
            "Epoch 343/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1999.6436 - mae: 1999.6436 - mse: 21233600.0000 - val_loss: 2538.2993 - val_mae: 2538.2993 - val_mse: 21658530.0000\n",
            "Epoch 344/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1976.8223 - mae: 1976.8223 - mse: 21258866.0000 - val_loss: 2252.7004 - val_mae: 2252.7004 - val_mse: 21494018.0000\n",
            "Epoch 345/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1934.2249 - mae: 1934.2249 - mse: 21113608.0000 - val_loss: 2176.3560 - val_mae: 2176.3560 - val_mse: 19967424.0000\n",
            "Epoch 346/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2023.6643 - mae: 2023.6643 - mse: 21704056.0000 - val_loss: 1863.4370 - val_mae: 1863.4370 - val_mse: 20401952.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 347/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1975.7996 - mae: 1975.7996 - mse: 21352312.0000 - val_loss: 2207.3396 - val_mae: 2207.3396 - val_mse: 20250284.0000\n",
            "Epoch 348/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1933.5519 - mae: 1933.5519 - mse: 21054310.0000 - val_loss: 2086.8835 - val_mae: 2086.8835 - val_mse: 21617766.0000\n",
            "Epoch 349/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2012.0321 - mae: 2012.0321 - mse: 21710076.0000 - val_loss: 2125.9492 - val_mae: 2125.9492 - val_mse: 20321340.0000\n",
            "Epoch 350/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1954.6385 - mae: 1954.6385 - mse: 21275292.0000 - val_loss: 1932.4781 - val_mae: 1932.4781 - val_mse: 21963186.0000\n",
            "Epoch 351/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1972.2140 - mae: 1972.2140 - mse: 21489918.0000 - val_loss: 1898.1464 - val_mae: 1898.1464 - val_mse: 21500260.0000\n",
            "Epoch 352/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1979.3055 - mae: 1979.3055 - mse: 21549942.0000 - val_loss: 2139.1292 - val_mae: 2139.1292 - val_mse: 20892526.0000\n",
            "Epoch 353/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1918.3206 - mae: 1918.3206 - mse: 21047346.0000 - val_loss: 1983.7502 - val_mae: 1983.7502 - val_mse: 20283964.0000\n",
            "Epoch 354/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1956.8751 - mae: 1956.8751 - mse: 21231034.0000 - val_loss: 1897.0447 - val_mae: 1897.0447 - val_mse: 20853024.0000\n",
            "Epoch 355/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2049.9812 - mae: 2049.9812 - mse: 21953734.0000 - val_loss: 1947.8096 - val_mae: 1947.8096 - val_mse: 22051192.0000\n",
            "Epoch 356/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1957.4121 - mae: 1957.4121 - mse: 21006028.0000 - val_loss: 2027.5024 - val_mae: 2027.5024 - val_mse: 21495184.0000\n",
            "Epoch 357/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1954.4553 - mae: 1954.4553 - mse: 21534270.0000 - val_loss: 1866.4792 - val_mae: 1866.4792 - val_mse: 20863512.0000\n",
            "Epoch 358/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2002.3199 - mae: 2002.3199 - mse: 21319458.0000 - val_loss: 1868.4292 - val_mae: 1868.4292 - val_mse: 20932726.0000\n",
            "Epoch 359/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1929.8425 - mae: 1929.8425 - mse: 21237326.0000 - val_loss: 2163.6528 - val_mae: 2163.6528 - val_mse: 20590966.0000\n",
            "Epoch 360/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2008.2345 - mae: 2008.2345 - mse: 21696816.0000 - val_loss: 2291.4233 - val_mae: 2291.4233 - val_mse: 20316132.0000\n",
            "Epoch 361/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1920.0822 - mae: 1920.0822 - mse: 21283898.0000 - val_loss: 2167.1260 - val_mae: 2167.1260 - val_mse: 22820600.0000\n",
            "Epoch 362/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1969.9562 - mae: 1969.9562 - mse: 21254726.0000 - val_loss: 1961.1831 - val_mae: 1961.1831 - val_mse: 20277988.0000\n",
            "Epoch 363/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1945.0530 - mae: 1945.0530 - mse: 20858998.0000 - val_loss: 2059.7275 - val_mae: 2059.7275 - val_mse: 22376980.0000\n",
            "Epoch 364/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1955.3816 - mae: 1955.3816 - mse: 21108320.0000 - val_loss: 2056.8887 - val_mae: 2056.8887 - val_mse: 20430910.0000\n",
            "Epoch 365/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1990.3319 - mae: 1990.3319 - mse: 21294176.0000 - val_loss: 1861.5820 - val_mae: 1861.5820 - val_mse: 21323852.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 366/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1937.3108 - mae: 1937.3108 - mse: 20892110.0000 - val_loss: 1968.7112 - val_mae: 1968.7112 - val_mse: 20426860.0000\n",
            "Epoch 367/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1960.6851 - mae: 1960.6851 - mse: 20954320.0000 - val_loss: 2297.8948 - val_mae: 2297.8948 - val_mse: 21473138.0000\n",
            "Epoch 368/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1980.5757 - mae: 1980.5757 - mse: 21321108.0000 - val_loss: 1950.0349 - val_mae: 1950.0349 - val_mse: 21229066.0000\n",
            "Epoch 369/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1938.4702 - mae: 1938.4702 - mse: 21359690.0000 - val_loss: 2350.9224 - val_mae: 2350.9224 - val_mse: 24303282.0000\n",
            "Epoch 370/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1961.8763 - mae: 1961.8763 - mse: 21219304.0000 - val_loss: 2125.3440 - val_mae: 2125.3440 - val_mse: 20922186.0000\n",
            "Epoch 371/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1979.7579 - mae: 1979.7579 - mse: 21437138.0000 - val_loss: 2271.0073 - val_mae: 2271.0073 - val_mse: 23964952.0000\n",
            "Epoch 372/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1896.8417 - mae: 1896.8417 - mse: 20519136.0000 - val_loss: 1927.1437 - val_mae: 1927.1437 - val_mse: 20068050.0000\n",
            "Epoch 373/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1969.3170 - mae: 1969.3170 - mse: 21497198.0000 - val_loss: 2459.7847 - val_mae: 2459.7847 - val_mse: 22748268.0000\n",
            "Epoch 374/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1943.4688 - mae: 1943.4688 - mse: 21106848.0000 - val_loss: 2169.0957 - val_mae: 2169.0957 - val_mse: 20599616.0000\n",
            "Epoch 375/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1936.0507 - mae: 1936.0507 - mse: 21057388.0000 - val_loss: 1837.1772 - val_mae: 1837.1772 - val_mse: 20426556.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 376/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1913.3531 - mae: 1913.3531 - mse: 20866626.0000 - val_loss: 2196.7310 - val_mae: 2196.7310 - val_mse: 20234058.0000\n",
            "Epoch 377/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1943.0104 - mae: 1943.0104 - mse: 20941078.0000 - val_loss: 1901.2538 - val_mae: 1901.2538 - val_mse: 21036778.0000\n",
            "Epoch 378/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1954.1583 - mae: 1954.1583 - mse: 21060118.0000 - val_loss: 1866.2225 - val_mae: 1866.2225 - val_mse: 20271386.0000\n",
            "Epoch 379/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1910.8589 - mae: 1910.8589 - mse: 20839660.0000 - val_loss: 2296.4573 - val_mae: 2296.4573 - val_mse: 24081628.0000\n",
            "Epoch 380/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1914.6632 - mae: 1914.6632 - mse: 20889810.0000 - val_loss: 1950.6923 - val_mae: 1950.6923 - val_mse: 21070332.0000\n",
            "Epoch 381/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1954.8953 - mae: 1954.8953 - mse: 21274174.0000 - val_loss: 2203.8513 - val_mae: 2203.8513 - val_mse: 22766844.0000\n",
            "Epoch 382/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1941.5739 - mae: 1941.5739 - mse: 21032500.0000 - val_loss: 2029.6320 - val_mae: 2029.6320 - val_mse: 21483520.0000\n",
            "Epoch 383/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1934.7053 - mae: 1934.7053 - mse: 20926168.0000 - val_loss: 2040.7101 - val_mae: 2040.7103 - val_mse: 21383102.0000\n",
            "Epoch 384/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1965.0214 - mae: 1965.0214 - mse: 21187044.0000 - val_loss: 1858.3201 - val_mae: 1858.3201 - val_mse: 20691346.0000\n",
            "Epoch 385/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1906.8384 - mae: 1906.8384 - mse: 20834068.0000 - val_loss: 1934.6102 - val_mae: 1934.6102 - val_mse: 21302702.0000\n",
            "Epoch 386/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1917.2632 - mae: 1917.2632 - mse: 20978348.0000 - val_loss: 2372.2451 - val_mae: 2372.2451 - val_mse: 24037062.0000\n",
            "Epoch 387/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1913.4543 - mae: 1913.4543 - mse: 21042778.0000 - val_loss: 2174.7065 - val_mae: 2174.7065 - val_mse: 20261800.0000\n",
            "Epoch 388/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1948.4822 - mae: 1948.4822 - mse: 21131168.0000 - val_loss: 2084.0103 - val_mae: 2084.0103 - val_mse: 21870760.0000\n",
            "Epoch 389/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1929.3171 - mae: 1929.3171 - mse: 20796510.0000 - val_loss: 1997.5676 - val_mae: 1997.5676 - val_mse: 20572102.0000\n",
            "Epoch 390/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1893.0437 - mae: 1893.0437 - mse: 20638598.0000 - val_loss: 1826.3140 - val_mae: 1826.3138 - val_mse: 20170036.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 391/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1940.8223 - mae: 1940.8223 - mse: 21360090.0000 - val_loss: 1808.9973 - val_mae: 1808.9973 - val_mse: 20613454.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 392/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1937.0575 - mae: 1937.0575 - mse: 20818748.0000 - val_loss: 2323.7449 - val_mae: 2323.7449 - val_mse: 24268032.0000\n",
            "Epoch 393/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1914.1293 - mae: 1914.1293 - mse: 20869776.0000 - val_loss: 2358.2649 - val_mae: 2358.2649 - val_mse: 24233362.0000\n",
            "Epoch 394/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1886.4143 - mae: 1886.4143 - mse: 20675288.0000 - val_loss: 2483.3994 - val_mae: 2483.3994 - val_mse: 21104672.0000\n",
            "Epoch 395/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1884.2029 - mae: 1884.2029 - mse: 20508158.0000 - val_loss: 2686.8762 - val_mae: 2686.8762 - val_mse: 27689354.0000\n",
            "Epoch 396/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1937.9473 - mae: 1937.9473 - mse: 21115080.0000 - val_loss: 2520.9895 - val_mae: 2520.9895 - val_mse: 23440028.0000\n",
            "Epoch 397/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1920.8606 - mae: 1920.8606 - mse: 20624046.0000 - val_loss: 1926.0594 - val_mae: 1926.0594 - val_mse: 20603208.0000\n",
            "Epoch 398/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1918.2269 - mae: 1918.2269 - mse: 21372302.0000 - val_loss: 2348.3130 - val_mae: 2348.3130 - val_mse: 24382842.0000\n",
            "Epoch 399/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1930.2605 - mae: 1930.2605 - mse: 21167590.0000 - val_loss: 2009.5170 - val_mae: 2009.5170 - val_mse: 21586862.0000\n",
            "Epoch 400/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1891.2726 - mae: 1891.2726 - mse: 20428090.0000 - val_loss: 2231.5437 - val_mae: 2231.5437 - val_mse: 23571722.0000\n",
            "Epoch 401/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1871.1698 - mae: 1871.1698 - mse: 20607682.0000 - val_loss: 1984.2487 - val_mae: 1984.2487 - val_mse: 21860366.0000\n",
            "Epoch 402/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1947.0217 - mae: 1947.0217 - mse: 20940862.0000 - val_loss: 1955.9541 - val_mae: 1955.9541 - val_mse: 20039322.0000\n",
            "Epoch 403/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1856.0641 - mae: 1856.0641 - mse: 20550828.0000 - val_loss: 2148.5857 - val_mae: 2148.5857 - val_mse: 19737104.0000\n",
            "Epoch 404/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1953.6390 - mae: 1953.6390 - mse: 20935194.0000 - val_loss: 1945.2041 - val_mae: 1945.2041 - val_mse: 20245834.0000\n",
            "Epoch 405/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1902.9294 - mae: 1902.9294 - mse: 20516232.0000 - val_loss: 2036.7157 - val_mae: 2036.7157 - val_mse: 21442644.0000\n",
            "Epoch 406/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1895.1223 - mae: 1895.1223 - mse: 20815066.0000 - val_loss: 1951.7877 - val_mae: 1951.7877 - val_mse: 20459594.0000\n",
            "Epoch 407/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1896.9839 - mae: 1896.9839 - mse: 20649060.0000 - val_loss: 2047.1675 - val_mae: 2047.1675 - val_mse: 21794752.0000\n",
            "Epoch 408/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1934.1920 - mae: 1934.1920 - mse: 20963502.0000 - val_loss: 2012.1921 - val_mae: 2012.1921 - val_mse: 22140084.0000\n",
            "Epoch 409/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1931.2321 - mae: 1931.2321 - mse: 20998522.0000 - val_loss: 2050.1521 - val_mae: 2050.1521 - val_mse: 20364154.0000\n",
            "Epoch 410/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1929.4091 - mae: 1929.4091 - mse: 20951270.0000 - val_loss: 1958.5726 - val_mae: 1958.5726 - val_mse: 20078292.0000\n",
            "Epoch 411/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1903.3474 - mae: 1903.3474 - mse: 21059784.0000 - val_loss: 1863.3003 - val_mae: 1863.3003 - val_mse: 21045992.0000\n",
            "Epoch 412/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1903.2267 - mae: 1903.2267 - mse: 20578180.0000 - val_loss: 1928.8715 - val_mae: 1928.8715 - val_mse: 20065082.0000\n",
            "Epoch 413/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1896.8474 - mae: 1896.8474 - mse: 20673608.0000 - val_loss: 2457.8318 - val_mae: 2457.8318 - val_mse: 24450922.0000\n",
            "Epoch 414/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1939.1676 - mae: 1939.1676 - mse: 20991724.0000 - val_loss: 2090.3911 - val_mae: 2090.3911 - val_mse: 22777620.0000\n",
            "Epoch 415/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1916.1748 - mae: 1916.1748 - mse: 20769404.0000 - val_loss: 2199.5537 - val_mae: 2199.5537 - val_mse: 23211304.0000\n",
            "Epoch 416/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1932.6903 - mae: 1932.6903 - mse: 20975504.0000 - val_loss: 2146.6638 - val_mae: 2146.6638 - val_mse: 22273848.0000\n",
            "Epoch 417/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1871.3702 - mae: 1871.3702 - mse: 20848250.0000 - val_loss: 2133.5168 - val_mae: 2133.5168 - val_mse: 22096576.0000\n",
            "Epoch 418/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1953.8851 - mae: 1953.8851 - mse: 21028402.0000 - val_loss: 1843.2990 - val_mae: 1843.2990 - val_mse: 20510290.0000\n",
            "Epoch 419/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1900.4078 - mae: 1900.4078 - mse: 20742684.0000 - val_loss: 1838.9753 - val_mae: 1838.9753 - val_mse: 20694564.0000\n",
            "Epoch 420/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1902.2361 - mae: 1902.2361 - mse: 20613616.0000 - val_loss: 1981.6687 - val_mae: 1981.6687 - val_mse: 22079268.0000\n",
            "Epoch 421/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1871.0289 - mae: 1871.0289 - mse: 20605980.0000 - val_loss: 2091.9021 - val_mae: 2091.9021 - val_mse: 20405158.0000\n",
            "Epoch 422/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1902.6517 - mae: 1902.6517 - mse: 20770072.0000 - val_loss: 1858.7297 - val_mae: 1858.7297 - val_mse: 21376014.0000\n",
            "Epoch 423/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1884.6940 - mae: 1884.6940 - mse: 20650242.0000 - val_loss: 1936.6063 - val_mae: 1936.6063 - val_mse: 20486116.0000\n",
            "Epoch 424/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1910.5330 - mae: 1910.5330 - mse: 20812130.0000 - val_loss: 2025.1903 - val_mae: 2025.1903 - val_mse: 21247050.0000\n",
            "Epoch 425/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1918.2657 - mae: 1918.2657 - mse: 20792054.0000 - val_loss: 1925.7479 - val_mae: 1925.7479 - val_mse: 20138138.0000\n",
            "Epoch 426/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1925.5154 - mae: 1925.5154 - mse: 21258386.0000 - val_loss: 2046.7004 - val_mae: 2046.7004 - val_mse: 20280214.0000\n",
            "Epoch 427/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1875.9220 - mae: 1875.9220 - mse: 20775572.0000 - val_loss: 2028.6412 - val_mae: 2028.6412 - val_mse: 21797672.0000\n",
            "Epoch 428/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1857.7067 - mae: 1857.7067 - mse: 20616818.0000 - val_loss: 2090.3909 - val_mae: 2090.3909 - val_mse: 22296952.0000\n",
            "Epoch 429/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1901.3987 - mae: 1901.3987 - mse: 20609440.0000 - val_loss: 2211.6899 - val_mae: 2211.6899 - val_mse: 20688120.0000\n",
            "Epoch 430/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1920.6252 - mae: 1920.6252 - mse: 20806350.0000 - val_loss: 1976.7639 - val_mae: 1976.7639 - val_mse: 21599228.0000\n",
            "Epoch 431/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1868.8451 - mae: 1868.8451 - mse: 20431262.0000 - val_loss: 1899.4407 - val_mae: 1899.4407 - val_mse: 21536064.0000\n",
            "Epoch 432/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1882.3230 - mae: 1882.3230 - mse: 20521864.0000 - val_loss: 1877.2952 - val_mae: 1877.2952 - val_mse: 20223426.0000\n",
            "Epoch 433/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1905.6669 - mae: 1905.6669 - mse: 20808590.0000 - val_loss: 2247.3105 - val_mae: 2247.3105 - val_mse: 20715908.0000\n",
            "Epoch 434/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1860.3734 - mae: 1860.3734 - mse: 20343176.0000 - val_loss: 1996.5973 - val_mae: 1996.5973 - val_mse: 22287160.0000\n",
            "Epoch 435/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1934.6935 - mae: 1934.6935 - mse: 20907320.0000 - val_loss: 1828.4679 - val_mae: 1828.4679 - val_mse: 20330704.0000\n",
            "Epoch 436/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1842.8555 - mae: 1842.8555 - mse: 20142188.0000 - val_loss: 2257.6240 - val_mae: 2257.6240 - val_mse: 22060616.0000\n",
            "Epoch 437/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1904.5563 - mae: 1904.5563 - mse: 20794046.0000 - val_loss: 1959.5675 - val_mae: 1959.5675 - val_mse: 21701192.0000\n",
            "Epoch 438/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1922.3422 - mae: 1922.3422 - mse: 21033896.0000 - val_loss: 2137.4543 - val_mae: 2137.4543 - val_mse: 23853982.0000\n",
            "Epoch 439/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1848.3451 - mae: 1848.3451 - mse: 20242704.0000 - val_loss: 1996.0900 - val_mae: 1996.0900 - val_mse: 20141276.0000\n",
            "Epoch 440/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1903.5605 - mae: 1903.5605 - mse: 20920420.0000 - val_loss: 2393.1853 - val_mae: 2393.1853 - val_mse: 20755228.0000\n",
            "Epoch 441/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1955.5166 - mae: 1955.5166 - mse: 20855288.0000 - val_loss: 2170.7937 - val_mae: 2170.7937 - val_mse: 21767562.0000\n",
            "Epoch 442/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1917.8229 - mae: 1917.8229 - mse: 20852324.0000 - val_loss: 2209.5391 - val_mae: 2209.5391 - val_mse: 22728972.0000\n",
            "Epoch 443/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1883.9143 - mae: 1883.9143 - mse: 20653042.0000 - val_loss: 1806.0428 - val_mae: 1806.0428 - val_mse: 20769428.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 444/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1900.1821 - mae: 1900.1821 - mse: 20875976.0000 - val_loss: 1839.3864 - val_mae: 1839.3864 - val_mse: 21019486.0000\n",
            "Epoch 445/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1835.8569 - mae: 1835.8569 - mse: 20381552.0000 - val_loss: 2424.5525 - val_mae: 2424.5525 - val_mse: 24185718.0000\n",
            "Epoch 446/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1917.8990 - mae: 1917.8990 - mse: 20952798.0000 - val_loss: 1869.0254 - val_mae: 1869.0254 - val_mse: 20450370.0000\n",
            "Epoch 447/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1863.4423 - mae: 1863.4423 - mse: 20388414.0000 - val_loss: 2323.3325 - val_mae: 2323.3325 - val_mse: 23598688.0000\n",
            "Epoch 448/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1917.7466 - mae: 1917.7466 - mse: 20994938.0000 - val_loss: 1788.7343 - val_mae: 1788.7343 - val_mse: 20779698.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 449/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1859.1801 - mae: 1859.1801 - mse: 20635604.0000 - val_loss: 2163.7043 - val_mae: 2163.7043 - val_mse: 20447476.0000\n",
            "Epoch 450/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1917.5950 - mae: 1917.5950 - mse: 20656142.0000 - val_loss: 1878.1273 - val_mae: 1878.1273 - val_mse: 20122904.0000\n",
            "Epoch 451/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1849.2141 - mae: 1849.2141 - mse: 20394228.0000 - val_loss: 1862.8639 - val_mae: 1862.8639 - val_mse: 20605102.0000\n",
            "Epoch 452/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1918.1360 - mae: 1918.1360 - mse: 21376976.0000 - val_loss: 1908.7418 - val_mae: 1908.7418 - val_mse: 20414782.0000\n",
            "Epoch 453/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1861.6161 - mae: 1861.6161 - mse: 20508062.0000 - val_loss: 2112.6868 - val_mae: 2112.6868 - val_mse: 21176294.0000\n",
            "Epoch 454/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1862.3175 - mae: 1862.3175 - mse: 20226326.0000 - val_loss: 1909.8187 - val_mae: 1909.8187 - val_mse: 20562198.0000\n",
            "Epoch 455/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1863.7264 - mae: 1863.7264 - mse: 20374228.0000 - val_loss: 1736.0137 - val_mae: 1736.0137 - val_mse: 20035420.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 456/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1852.3265 - mae: 1852.3265 - mse: 20397664.0000 - val_loss: 2012.9410 - val_mae: 2012.9410 - val_mse: 19653612.0000\n",
            "Epoch 457/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1898.2361 - mae: 1898.2361 - mse: 20537400.0000 - val_loss: 2301.8345 - val_mae: 2301.8345 - val_mse: 20445778.0000\n",
            "Epoch 458/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1855.8087 - mae: 1855.8087 - mse: 20012120.0000 - val_loss: 2274.8762 - val_mae: 2274.8762 - val_mse: 23481032.0000\n",
            "Epoch 459/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1861.0680 - mae: 1861.0680 - mse: 20642058.0000 - val_loss: 2107.0706 - val_mae: 2107.0706 - val_mse: 20173592.0000\n",
            "Epoch 460/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1861.0969 - mae: 1861.0969 - mse: 20575316.0000 - val_loss: 1923.2343 - val_mae: 1923.2343 - val_mse: 21792314.0000\n",
            "Epoch 461/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1852.6969 - mae: 1852.6969 - mse: 20336562.0000 - val_loss: 1892.7168 - val_mae: 1892.7168 - val_mse: 20557522.0000\n",
            "Epoch 462/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1874.5273 - mae: 1874.5273 - mse: 20735538.0000 - val_loss: 1967.2012 - val_mae: 1967.2012 - val_mse: 21331466.0000\n",
            "Epoch 463/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1856.9941 - mae: 1856.9941 - mse: 20477334.0000 - val_loss: 1841.1578 - val_mae: 1841.1578 - val_mse: 20883074.0000\n",
            "Epoch 464/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1857.6277 - mae: 1857.6277 - mse: 20254322.0000 - val_loss: 1789.8756 - val_mae: 1789.8756 - val_mse: 20455672.0000\n",
            "Epoch 465/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1847.6289 - mae: 1847.6289 - mse: 20602416.0000 - val_loss: 2111.9175 - val_mae: 2111.9175 - val_mse: 22519340.0000\n",
            "Epoch 466/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1886.0702 - mae: 1886.0702 - mse: 20552354.0000 - val_loss: 2202.0769 - val_mae: 2202.0769 - val_mse: 24624790.0000\n",
            "Epoch 467/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1872.2449 - mae: 1872.2449 - mse: 20707070.0000 - val_loss: 2013.1945 - val_mae: 2013.1945 - val_mse: 21732030.0000\n",
            "Epoch 468/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1851.8510 - mae: 1851.8510 - mse: 20482350.0000 - val_loss: 1920.7024 - val_mae: 1920.7024 - val_mse: 19965454.0000\n",
            "Epoch 469/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1840.3567 - mae: 1840.3567 - mse: 20208066.0000 - val_loss: 2034.2417 - val_mae: 2034.2417 - val_mse: 20067708.0000\n",
            "Epoch 470/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1870.3026 - mae: 1870.3026 - mse: 20522536.0000 - val_loss: 1922.7837 - val_mae: 1922.7837 - val_mse: 21539426.0000\n",
            "Epoch 471/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1847.8859 - mae: 1847.8859 - mse: 20493138.0000 - val_loss: 1865.3453 - val_mae: 1865.3453 - val_mse: 21055124.0000\n",
            "Epoch 472/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1900.3512 - mae: 1900.3512 - mse: 20670674.0000 - val_loss: 1841.4062 - val_mae: 1841.4062 - val_mse: 20142014.0000\n",
            "Epoch 473/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1881.1344 - mae: 1881.1344 - mse: 20849858.0000 - val_loss: 1832.6094 - val_mae: 1832.6094 - val_mse: 19733994.0000\n",
            "Epoch 474/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1849.0295 - mae: 1849.0295 - mse: 20455278.0000 - val_loss: 2150.8638 - val_mae: 2150.8638 - val_mse: 24396264.0000\n",
            "Epoch 475/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1877.7246 - mae: 1877.7246 - mse: 20995642.0000 - val_loss: 1930.9659 - val_mae: 1930.9659 - val_mse: 20920820.0000\n",
            "Epoch 476/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1845.8541 - mae: 1845.8541 - mse: 20374356.0000 - val_loss: 2312.2393 - val_mae: 2312.2393 - val_mse: 24759380.0000\n",
            "Epoch 477/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1832.0565 - mae: 1832.0565 - mse: 20561864.0000 - val_loss: 2225.0193 - val_mae: 2225.0193 - val_mse: 23083542.0000\n",
            "Epoch 478/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1877.2300 - mae: 1877.2300 - mse: 20722046.0000 - val_loss: 2030.0211 - val_mae: 2030.0211 - val_mse: 22507974.0000\n",
            "Epoch 479/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1800.7988 - mae: 1800.7988 - mse: 20279196.0000 - val_loss: 2335.7495 - val_mae: 2335.7495 - val_mse: 20493868.0000\n",
            "Epoch 480/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1884.8302 - mae: 1884.8302 - mse: 20757428.0000 - val_loss: 2052.0964 - val_mae: 2052.0964 - val_mse: 23324242.0000\n",
            "Epoch 481/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1818.0546 - mae: 1818.0546 - mse: 20380380.0000 - val_loss: 2066.8936 - val_mae: 2066.8936 - val_mse: 19874606.0000\n",
            "Epoch 482/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1859.4821 - mae: 1859.4821 - mse: 20569670.0000 - val_loss: 1992.1340 - val_mae: 1992.1340 - val_mse: 22302332.0000\n",
            "Epoch 483/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1804.3535 - mae: 1804.3535 - mse: 20104922.0000 - val_loss: 2054.4829 - val_mae: 2054.4829 - val_mse: 21930634.0000\n",
            "Epoch 484/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1878.5872 - mae: 1878.5872 - mse: 20680220.0000 - val_loss: 2119.2732 - val_mae: 2119.2732 - val_mse: 19841600.0000\n",
            "Epoch 485/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1847.8737 - mae: 1847.8737 - mse: 20459960.0000 - val_loss: 1767.0497 - val_mae: 1767.0497 - val_mse: 20600268.0000\n",
            "Epoch 486/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1861.9331 - mae: 1861.9331 - mse: 20492650.0000 - val_loss: 1841.0812 - val_mae: 1841.0812 - val_mse: 20830330.0000\n",
            "Epoch 487/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1846.5708 - mae: 1846.5708 - mse: 20322002.0000 - val_loss: 2213.9680 - val_mae: 2213.9680 - val_mse: 20989636.0000\n",
            "Epoch 488/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1829.5090 - mae: 1829.5090 - mse: 20291482.0000 - val_loss: 1754.0808 - val_mae: 1754.0808 - val_mse: 20390658.0000\n",
            "Epoch 489/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1819.1361 - mae: 1819.1361 - mse: 20329250.0000 - val_loss: 1925.2358 - val_mae: 1925.2358 - val_mse: 20001324.0000\n",
            "Epoch 490/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1793.7627 - mae: 1793.7627 - mse: 20187904.0000 - val_loss: 2309.5027 - val_mae: 2309.5027 - val_mse: 20325506.0000\n",
            "Epoch 491/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1816.9124 - mae: 1816.9124 - mse: 20553604.0000 - val_loss: 2141.7800 - val_mae: 2141.7800 - val_mse: 22629952.0000\n",
            "Epoch 492/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1806.0958 - mae: 1806.0958 - mse: 20311726.0000 - val_loss: 1790.5035 - val_mae: 1790.5035 - val_mse: 19588448.0000\n",
            "Epoch 493/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1818.3853 - mae: 1818.3853 - mse: 20257288.0000 - val_loss: 1977.7397 - val_mae: 1977.7397 - val_mse: 20510638.0000\n",
            "Epoch 494/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1803.2721 - mae: 1803.2721 - mse: 19796608.0000 - val_loss: 2031.3549 - val_mae: 2031.3549 - val_mse: 23123838.0000\n",
            "Epoch 495/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1813.1840 - mae: 1813.1840 - mse: 20063384.0000 - val_loss: 2065.2749 - val_mae: 2065.2749 - val_mse: 19663066.0000\n",
            "Epoch 496/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1847.6257 - mae: 1847.6257 - mse: 20072190.0000 - val_loss: 2304.7947 - val_mae: 2304.7947 - val_mse: 19940038.0000\n",
            "Epoch 497/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1813.2937 - mae: 1813.2937 - mse: 20189066.0000 - val_loss: 1886.9296 - val_mae: 1886.9296 - val_mse: 20736220.0000\n",
            "Epoch 498/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1832.5714 - mae: 1832.5714 - mse: 20702892.0000 - val_loss: 2013.1635 - val_mae: 2013.1635 - val_mse: 22308778.0000\n",
            "Epoch 499/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1801.3009 - mae: 1801.3009 - mse: 20278452.0000 - val_loss: 1864.1731 - val_mae: 1864.1731 - val_mse: 20388696.0000\n",
            "Epoch 500/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1785.6669 - mae: 1785.6669 - mse: 20266542.0000 - val_loss: 1996.6389 - val_mae: 1996.6389 - val_mse: 22463266.0000\n",
            "Epoch 501/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1796.7579 - mae: 1796.7579 - mse: 19924070.0000 - val_loss: 1880.6669 - val_mae: 1880.6669 - val_mse: 21847898.0000\n",
            "Epoch 502/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1841.7986 - mae: 1841.7986 - mse: 20531278.0000 - val_loss: 2018.1305 - val_mae: 2018.1305 - val_mse: 22386954.0000\n",
            "Epoch 503/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1810.9515 - mae: 1810.9515 - mse: 20280672.0000 - val_loss: 1791.2584 - val_mae: 1791.2584 - val_mse: 20177034.0000\n",
            "Epoch 504/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1706.0671 - mae: 1706.0671 - mse: 19694462.0000 - val_loss: 2525.5891 - val_mae: 2525.5891 - val_mse: 23489564.0000\n",
            "Epoch 505/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1804.9363 - mae: 1804.9363 - mse: 20038402.0000 - val_loss: 2363.7056 - val_mae: 2363.7056 - val_mse: 20308200.0000\n",
            "Epoch 506/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1823.7329 - mae: 1823.7329 - mse: 20119890.0000 - val_loss: 1911.3126 - val_mae: 1911.3126 - val_mse: 21422422.0000\n",
            "Epoch 507/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1787.5902 - mae: 1787.5902 - mse: 20231302.0000 - val_loss: 1926.7751 - val_mae: 1926.7751 - val_mse: 21319510.0000\n",
            "Epoch 508/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1770.2926 - mae: 1770.2926 - mse: 19977082.0000 - val_loss: 2152.6616 - val_mae: 2152.6616 - val_mse: 20727508.0000\n",
            "Epoch 509/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1823.1921 - mae: 1823.1921 - mse: 20316368.0000 - val_loss: 1813.8973 - val_mae: 1813.8973 - val_mse: 20383306.0000\n",
            "Epoch 510/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1810.4823 - mae: 1810.4823 - mse: 20252134.0000 - val_loss: 1715.9305 - val_mae: 1715.9305 - val_mse: 20708710.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 511/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1790.1450 - mae: 1790.1450 - mse: 19995942.0000 - val_loss: 1697.6710 - val_mae: 1697.6710 - val_mse: 19934012.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 512/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1721.3547 - mae: 1721.3547 - mse: 19848046.0000 - val_loss: 1779.0914 - val_mae: 1779.0914 - val_mse: 20641464.0000\n",
            "Epoch 513/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1780.7858 - mae: 1780.7858 - mse: 19900244.0000 - val_loss: 1893.3989 - val_mae: 1893.3989 - val_mse: 21423126.0000\n",
            "Epoch 514/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1804.6475 - mae: 1804.6475 - mse: 20477106.0000 - val_loss: 1816.5957 - val_mae: 1816.5957 - val_mse: 21184826.0000\n",
            "Epoch 515/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1786.5662 - mae: 1786.5662 - mse: 19846536.0000 - val_loss: 1953.0863 - val_mae: 1953.0863 - val_mse: 20026892.0000\n",
            "Epoch 516/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1790.6490 - mae: 1790.6490 - mse: 20378206.0000 - val_loss: 1976.1122 - val_mae: 1976.1122 - val_mse: 21570544.0000\n",
            "Epoch 517/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1796.6591 - mae: 1796.6591 - mse: 20514026.0000 - val_loss: 1716.2745 - val_mae: 1716.2745 - val_mse: 20224930.0000\n",
            "Epoch 518/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1760.7573 - mae: 1760.7573 - mse: 19812544.0000 - val_loss: 2329.7871 - val_mae: 2329.7871 - val_mse: 24297560.0000\n",
            "Epoch 519/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1807.8572 - mae: 1807.8572 - mse: 20278280.0000 - val_loss: 1827.1692 - val_mae: 1827.1692 - val_mse: 20772832.0000\n",
            "Epoch 520/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1801.4873 - mae: 1801.4873 - mse: 19865004.0000 - val_loss: 1833.4523 - val_mae: 1833.4523 - val_mse: 19495448.0000\n",
            "Epoch 521/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1804.8080 - mae: 1804.8080 - mse: 20272250.0000 - val_loss: 2014.2329 - val_mae: 2014.2329 - val_mse: 21990770.0000\n",
            "Epoch 522/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1764.3031 - mae: 1764.3031 - mse: 19978766.0000 - val_loss: 1984.2216 - val_mae: 1984.2217 - val_mse: 21843954.0000\n",
            "Epoch 523/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1778.2738 - mae: 1778.2738 - mse: 20003192.0000 - val_loss: 1742.2606 - val_mae: 1742.2606 - val_mse: 20067204.0000\n",
            "Epoch 524/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1752.2828 - mae: 1752.2828 - mse: 19733114.0000 - val_loss: 1953.6304 - val_mae: 1953.6304 - val_mse: 20647208.0000\n",
            "Epoch 525/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1796.1583 - mae: 1796.1583 - mse: 19841384.0000 - val_loss: 1881.8695 - val_mae: 1881.8695 - val_mse: 21482964.0000\n",
            "Epoch 526/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1756.4036 - mae: 1756.4036 - mse: 20170436.0000 - val_loss: 1932.7358 - val_mae: 1932.7358 - val_mse: 20105512.0000\n",
            "Epoch 527/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1769.9279 - mae: 1769.9279 - mse: 20016166.0000 - val_loss: 1890.9410 - val_mae: 1890.9410 - val_mse: 22846282.0000\n",
            "Epoch 528/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1762.5490 - mae: 1762.5490 - mse: 19937134.0000 - val_loss: 2086.4841 - val_mae: 2086.4841 - val_mse: 19878790.0000\n",
            "Epoch 529/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1740.4017 - mae: 1740.4017 - mse: 19828044.0000 - val_loss: 2006.1116 - val_mae: 2006.1116 - val_mse: 19143992.0000\n",
            "Epoch 530/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1779.6342 - mae: 1779.6342 - mse: 20043992.0000 - val_loss: 1833.9283 - val_mae: 1833.9283 - val_mse: 21146364.0000\n",
            "Epoch 531/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1710.9640 - mae: 1710.9640 - mse: 19462798.0000 - val_loss: 1832.4678 - val_mae: 1832.4678 - val_mse: 21386664.0000\n",
            "Epoch 532/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1742.6115 - mae: 1742.6115 - mse: 19872166.0000 - val_loss: 1802.5325 - val_mae: 1802.5325 - val_mse: 19844496.0000\n",
            "Epoch 533/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1724.5377 - mae: 1724.5377 - mse: 19945146.0000 - val_loss: 2364.6995 - val_mae: 2364.6995 - val_mse: 20556482.0000\n",
            "Epoch 534/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1745.4121 - mae: 1745.4121 - mse: 19883768.0000 - val_loss: 1698.4127 - val_mae: 1698.4127 - val_mse: 20283550.0000\n",
            "Epoch 535/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1744.9395 - mae: 1744.9395 - mse: 20113142.0000 - val_loss: 2099.9827 - val_mae: 2099.9827 - val_mse: 20064432.0000\n",
            "Epoch 536/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1727.7666 - mae: 1727.7666 - mse: 20149544.0000 - val_loss: 1946.9283 - val_mae: 1946.9283 - val_mse: 22050448.0000\n",
            "Epoch 537/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1750.9607 - mae: 1750.9607 - mse: 19906366.0000 - val_loss: 2128.3230 - val_mae: 2128.3230 - val_mse: 19662856.0000\n",
            "Epoch 538/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1744.2793 - mae: 1744.2793 - mse: 19586912.0000 - val_loss: 2047.4185 - val_mae: 2047.4185 - val_mse: 19706974.0000\n",
            "Epoch 539/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1714.7759 - mae: 1714.7759 - mse: 19878322.0000 - val_loss: 2029.4397 - val_mae: 2029.4397 - val_mse: 20257026.0000\n",
            "Epoch 540/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1757.3647 - mae: 1757.3647 - mse: 20302924.0000 - val_loss: 1742.2690 - val_mae: 1742.2690 - val_mse: 21191986.0000\n",
            "Epoch 541/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1746.4861 - mae: 1746.4861 - mse: 20135444.0000 - val_loss: 1677.9204 - val_mae: 1677.9204 - val_mse: 20413390.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 542/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1715.5906 - mae: 1715.5906 - mse: 19684518.0000 - val_loss: 2158.4937 - val_mae: 2158.4937 - val_mse: 23660690.0000\n",
            "Epoch 543/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1743.7473 - mae: 1743.7473 - mse: 19824884.0000 - val_loss: 1747.0347 - val_mae: 1747.0347 - val_mse: 20265288.0000\n",
            "Epoch 544/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1795.5645 - mae: 1795.5645 - mse: 20056560.0000 - val_loss: 1825.2029 - val_mae: 1825.2029 - val_mse: 19873772.0000\n",
            "Epoch 545/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1699.7328 - mae: 1699.7328 - mse: 19531168.0000 - val_loss: 2069.4280 - val_mae: 2069.4280 - val_mse: 19515466.0000\n",
            "Epoch 546/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1709.8661 - mae: 1709.8661 - mse: 19300826.0000 - val_loss: 1789.6281 - val_mae: 1789.6281 - val_mse: 20858100.0000\n",
            "Epoch 547/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1727.9397 - mae: 1727.9397 - mse: 20232858.0000 - val_loss: 1947.6051 - val_mae: 1947.6051 - val_mse: 19623920.0000\n",
            "Epoch 548/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1749.0471 - mae: 1749.0471 - mse: 19690022.0000 - val_loss: 2075.7383 - val_mae: 2075.7383 - val_mse: 19861258.0000\n",
            "Epoch 549/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1702.8696 - mae: 1702.8696 - mse: 19657254.0000 - val_loss: 1690.4008 - val_mae: 1690.4008 - val_mse: 20011898.0000\n",
            "Epoch 550/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1740.8298 - mae: 1740.8298 - mse: 19745484.0000 - val_loss: 1680.8201 - val_mae: 1680.8201 - val_mse: 20145226.0000\n",
            "Epoch 551/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1699.3397 - mae: 1699.3397 - mse: 19810570.0000 - val_loss: 2068.1313 - val_mae: 2068.1313 - val_mse: 19736658.0000\n",
            "Epoch 552/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1705.9688 - mae: 1705.9688 - mse: 19685776.0000 - val_loss: 2132.5918 - val_mae: 2132.5918 - val_mse: 19690768.0000\n",
            "Epoch 553/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1719.1627 - mae: 1719.1627 - mse: 19799030.0000 - val_loss: 1698.7197 - val_mae: 1698.7197 - val_mse: 20430446.0000\n",
            "Epoch 554/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1720.6881 - mae: 1720.6881 - mse: 19817854.0000 - val_loss: 2360.5303 - val_mae: 2360.5303 - val_mse: 24438532.0000\n",
            "Epoch 555/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1738.8132 - mae: 1738.8132 - mse: 20155382.0000 - val_loss: 1825.1656 - val_mae: 1825.1656 - val_mse: 20717832.0000\n",
            "Epoch 556/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1679.8716 - mae: 1679.8716 - mse: 19626488.0000 - val_loss: 1938.2726 - val_mae: 1938.2726 - val_mse: 19603494.0000\n",
            "Epoch 557/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1717.7501 - mae: 1717.7501 - mse: 19593038.0000 - val_loss: 2011.4873 - val_mae: 2011.4873 - val_mse: 20101184.0000\n",
            "Epoch 558/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1702.5735 - mae: 1702.5735 - mse: 19416490.0000 - val_loss: 2150.6001 - val_mae: 2150.6001 - val_mse: 24308848.0000\n",
            "Epoch 559/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1698.5709 - mae: 1698.5709 - mse: 19846488.0000 - val_loss: 1859.7908 - val_mae: 1859.7908 - val_mse: 19626930.0000\n",
            "Epoch 560/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1723.2532 - mae: 1723.2532 - mse: 19826524.0000 - val_loss: 2507.0042 - val_mae: 2507.0042 - val_mse: 26428148.0000\n",
            "Epoch 561/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1675.9546 - mae: 1675.9546 - mse: 19604124.0000 - val_loss: 1887.4633 - val_mae: 1887.4633 - val_mse: 21764402.0000\n",
            "Epoch 562/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1698.0417 - mae: 1698.0417 - mse: 19734518.0000 - val_loss: 1964.1508 - val_mae: 1964.1508 - val_mse: 19839976.0000\n",
            "Epoch 563/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1720.1793 - mae: 1720.1793 - mse: 19622414.0000 - val_loss: 1726.4291 - val_mae: 1726.4291 - val_mse: 19977914.0000\n",
            "Epoch 564/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.8325 - mae: 1665.8325 - mse: 19464652.0000 - val_loss: 1734.5769 - val_mae: 1734.5769 - val_mse: 20935902.0000\n",
            "Epoch 565/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1710.9459 - mae: 1710.9459 - mse: 19809440.0000 - val_loss: 2159.0225 - val_mae: 2159.0225 - val_mse: 19750202.0000\n",
            "Epoch 566/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1676.5699 - mae: 1676.5699 - mse: 19448166.0000 - val_loss: 1837.2152 - val_mae: 1837.2152 - val_mse: 20792120.0000\n",
            "Epoch 567/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1690.8615 - mae: 1690.8615 - mse: 19674584.0000 - val_loss: 2136.3716 - val_mae: 2136.3716 - val_mse: 19453804.0000\n",
            "Epoch 568/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1693.9821 - mae: 1693.9821 - mse: 19609880.0000 - val_loss: 2123.3262 - val_mae: 2123.3262 - val_mse: 23461938.0000\n",
            "Epoch 569/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1707.9180 - mae: 1707.9180 - mse: 19823104.0000 - val_loss: 1965.2798 - val_mae: 1965.2798 - val_mse: 20280376.0000\n",
            "Epoch 570/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1686.7219 - mae: 1686.7219 - mse: 19593342.0000 - val_loss: 1907.6512 - val_mae: 1907.6512 - val_mse: 19945784.0000\n",
            "Epoch 571/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1731.2107 - mae: 1731.2107 - mse: 20012070.0000 - val_loss: 1753.9280 - val_mae: 1753.9280 - val_mse: 20556848.0000\n",
            "Epoch 572/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.2498 - mae: 1665.2498 - mse: 19562110.0000 - val_loss: 2078.9021 - val_mae: 2078.9021 - val_mse: 23518808.0000\n",
            "Epoch 573/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1710.2551 - mae: 1710.2551 - mse: 19957694.0000 - val_loss: 2059.8357 - val_mae: 2059.8357 - val_mse: 22618662.0000\n",
            "Epoch 574/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1723.3110 - mae: 1723.3110 - mse: 19569228.0000 - val_loss: 1729.3582 - val_mae: 1729.3582 - val_mse: 20327634.0000\n",
            "Epoch 575/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1687.9987 - mae: 1687.9987 - mse: 19578034.0000 - val_loss: 1899.8987 - val_mae: 1899.8987 - val_mse: 22763204.0000\n",
            "Epoch 576/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1696.9921 - mae: 1696.9921 - mse: 19752800.0000 - val_loss: 1846.2115 - val_mae: 1846.2115 - val_mse: 19743570.0000\n",
            "Epoch 577/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1665.0276 - mae: 1665.0276 - mse: 19254676.0000 - val_loss: 2262.3474 - val_mae: 2262.3474 - val_mse: 23727228.0000\n",
            "Epoch 578/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1737.1575 - mae: 1737.1575 - mse: 20102900.0000 - val_loss: 1706.8362 - val_mae: 1706.8362 - val_mse: 20624226.0000\n",
            "Epoch 579/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.8398 - mae: 1665.8398 - mse: 19500116.0000 - val_loss: 1985.5660 - val_mae: 1985.5662 - val_mse: 19670150.0000\n",
            "Epoch 580/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1697.5824 - mae: 1697.5824 - mse: 19909738.0000 - val_loss: 1891.1587 - val_mae: 1891.1587 - val_mse: 19376124.0000\n",
            "Epoch 581/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1693.4240 - mae: 1693.4240 - mse: 19500238.0000 - val_loss: 2008.2695 - val_mae: 2008.2695 - val_mse: 22322814.0000\n",
            "Epoch 582/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1664.9708 - mae: 1664.9708 - mse: 19355928.0000 - val_loss: 1789.5444 - val_mae: 1789.5444 - val_mse: 21312840.0000\n",
            "Epoch 583/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1693.5079 - mae: 1693.5079 - mse: 19712046.0000 - val_loss: 1805.8287 - val_mae: 1805.8287 - val_mse: 21536182.0000\n",
            "Epoch 584/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1658.7896 - mae: 1658.7896 - mse: 19464982.0000 - val_loss: 2241.7893 - val_mae: 2241.7893 - val_mse: 23795522.0000\n",
            "Epoch 585/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1664.0155 - mae: 1664.0155 - mse: 19302274.0000 - val_loss: 1696.3170 - val_mae: 1696.3170 - val_mse: 20909016.0000\n",
            "Epoch 586/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1714.9500 - mae: 1714.9500 - mse: 19736804.0000 - val_loss: 1930.7858 - val_mae: 1930.7858 - val_mse: 19951502.0000\n",
            "Epoch 587/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1652.8641 - mae: 1652.8641 - mse: 19395612.0000 - val_loss: 2076.4016 - val_mae: 2076.4016 - val_mse: 22633010.0000\n",
            "Epoch 588/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1689.3478 - mae: 1689.3478 - mse: 19780134.0000 - val_loss: 1877.0586 - val_mae: 1877.0586 - val_mse: 22478966.0000\n",
            "Epoch 589/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1682.5342 - mae: 1682.5342 - mse: 19777414.0000 - val_loss: 2061.0840 - val_mae: 2061.0840 - val_mse: 19766378.0000\n",
            "Epoch 590/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1647.7399 - mae: 1647.7399 - mse: 19347368.0000 - val_loss: 2143.8625 - val_mae: 2143.8625 - val_mse: 19921306.0000\n",
            "Epoch 591/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1705.6156 - mae: 1705.6156 - mse: 19828350.0000 - val_loss: 1770.3378 - val_mae: 1770.3378 - val_mse: 20393810.0000\n",
            "Epoch 592/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1662.6094 - mae: 1662.6094 - mse: 19688270.0000 - val_loss: 2254.7708 - val_mae: 2254.7708 - val_mse: 25511130.0000\n",
            "Epoch 593/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1702.3342 - mae: 1702.3342 - mse: 19904508.0000 - val_loss: 1665.2959 - val_mae: 1665.2959 - val_mse: 20065192.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 594/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1689.9767 - mae: 1689.9767 - mse: 19831028.0000 - val_loss: 1640.8752 - val_mae: 1640.8752 - val_mse: 19831372.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 595/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1631.1367 - mae: 1631.1367 - mse: 19665234.0000 - val_loss: 1796.7039 - val_mae: 1796.7039 - val_mse: 20645324.0000\n",
            "Epoch 596/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1687.3065 - mae: 1687.3065 - mse: 19925912.0000 - val_loss: 1786.9053 - val_mae: 1786.9053 - val_mse: 21529076.0000\n",
            "Epoch 597/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1677.6025 - mae: 1677.6025 - mse: 19629824.0000 - val_loss: 2042.7426 - val_mae: 2042.7426 - val_mse: 23060952.0000\n",
            "Epoch 598/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1694.4991 - mae: 1694.4991 - mse: 20033712.0000 - val_loss: 1815.7567 - val_mae: 1815.7567 - val_mse: 19444938.0000\n",
            "Epoch 599/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1666.0054 - mae: 1666.0054 - mse: 19518498.0000 - val_loss: 1818.6296 - val_mae: 1818.6296 - val_mse: 21169826.0000\n",
            "Epoch 600/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1649.4806 - mae: 1649.4806 - mse: 19204110.0000 - val_loss: 1787.7352 - val_mae: 1787.7352 - val_mse: 21181132.0000\n",
            "Epoch 601/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1672.0215 - mae: 1672.0215 - mse: 19571144.0000 - val_loss: 1705.3733 - val_mae: 1705.3733 - val_mse: 20609892.0000\n",
            "Epoch 602/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1697.2036 - mae: 1697.2036 - mse: 19798074.0000 - val_loss: 1994.1233 - val_mae: 1994.1233 - val_mse: 20196046.0000\n",
            "Epoch 603/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1686.3137 - mae: 1686.3137 - mse: 19601584.0000 - val_loss: 1601.9131 - val_mae: 1601.9131 - val_mse: 19927798.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 604/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1653.1271 - mae: 1653.1271 - mse: 19439096.0000 - val_loss: 2205.9148 - val_mae: 2205.9148 - val_mse: 26909516.0000\n",
            "Epoch 605/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1681.2350 - mae: 1681.2350 - mse: 19569786.0000 - val_loss: 1696.0460 - val_mae: 1696.0460 - val_mse: 20246792.0000\n",
            "Epoch 606/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1675.9525 - mae: 1675.9525 - mse: 19654226.0000 - val_loss: 1749.6919 - val_mae: 1749.6919 - val_mse: 20834708.0000\n",
            "Epoch 607/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1670.0298 - mae: 1670.0298 - mse: 19497590.0000 - val_loss: 1849.8599 - val_mae: 1849.8599 - val_mse: 19448196.0000\n",
            "Epoch 608/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1703.6741 - mae: 1703.6741 - mse: 19560958.0000 - val_loss: 1942.2515 - val_mae: 1942.2515 - val_mse: 22392616.0000\n",
            "Epoch 609/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1633.9934 - mae: 1633.9934 - mse: 19456776.0000 - val_loss: 1689.5516 - val_mae: 1689.5516 - val_mse: 20198740.0000\n",
            "Epoch 610/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1672.8053 - mae: 1672.8053 - mse: 19893380.0000 - val_loss: 1672.9448 - val_mae: 1672.9448 - val_mse: 20260134.0000\n",
            "Epoch 611/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1664.5151 - mae: 1664.5151 - mse: 19317030.0000 - val_loss: 1952.9966 - val_mae: 1952.9966 - val_mse: 21976970.0000\n",
            "Epoch 612/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1645.0988 - mae: 1645.0988 - mse: 19193538.0000 - val_loss: 1912.7628 - val_mae: 1912.7628 - val_mse: 19512376.0000\n",
            "Epoch 613/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1701.4594 - mae: 1701.4594 - mse: 20063210.0000 - val_loss: 1865.2847 - val_mae: 1865.2847 - val_mse: 21786372.0000\n",
            "Epoch 614/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1667.9258 - mae: 1667.9258 - mse: 19430008.0000 - val_loss: 1993.7178 - val_mae: 1993.7178 - val_mse: 22081266.0000\n",
            "Epoch 615/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1646.8546 - mae: 1646.8546 - mse: 19251750.0000 - val_loss: 1723.5269 - val_mae: 1723.5269 - val_mse: 21044004.0000\n",
            "Epoch 616/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1646.4089 - mae: 1646.4089 - mse: 19283826.0000 - val_loss: 1829.9585 - val_mae: 1829.9585 - val_mse: 21369346.0000\n",
            "Epoch 617/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1604.1589 - mae: 1604.1589 - mse: 19331996.0000 - val_loss: 1706.8849 - val_mae: 1706.8849 - val_mse: 20947264.0000\n",
            "Epoch 618/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1682.8958 - mae: 1682.8958 - mse: 19546396.0000 - val_loss: 2116.5613 - val_mae: 2116.5613 - val_mse: 24001832.0000\n",
            "Epoch 619/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1654.5752 - mae: 1654.5752 - mse: 19611042.0000 - val_loss: 2074.6067 - val_mae: 2074.6067 - val_mse: 23946572.0000\n",
            "Epoch 620/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1648.7932 - mae: 1648.7932 - mse: 19540014.0000 - val_loss: 2137.7144 - val_mae: 2137.7144 - val_mse: 24541798.0000\n",
            "Epoch 621/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1646.7218 - mae: 1646.7218 - mse: 19501712.0000 - val_loss: 1937.1763 - val_mae: 1937.1763 - val_mse: 22808160.0000\n",
            "Epoch 622/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1647.5555 - mae: 1647.5555 - mse: 19636886.0000 - val_loss: 1682.4315 - val_mae: 1682.4315 - val_mse: 20680330.0000\n",
            "Epoch 623/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1655.9578 - mae: 1655.9578 - mse: 19285058.0000 - val_loss: 1662.1245 - val_mae: 1662.1245 - val_mse: 20327620.0000\n",
            "Epoch 624/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1643.3175 - mae: 1643.3175 - mse: 19419808.0000 - val_loss: 2035.6272 - val_mae: 2035.6272 - val_mse: 22914696.0000\n",
            "Epoch 625/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.5601 - mae: 1665.5601 - mse: 19539318.0000 - val_loss: 1909.1598 - val_mae: 1909.1598 - val_mse: 19846496.0000\n",
            "Epoch 626/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1675.8735 - mae: 1675.8735 - mse: 19895890.0000 - val_loss: 1754.0067 - val_mae: 1754.0067 - val_mse: 19971086.0000\n",
            "Epoch 627/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1666.2847 - mae: 1666.2847 - mse: 19558012.0000 - val_loss: 1612.6082 - val_mae: 1612.6082 - val_mse: 19999902.0000\n",
            "Epoch 628/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1683.8401 - mae: 1683.8401 - mse: 19827558.0000 - val_loss: 1979.5179 - val_mae: 1979.5179 - val_mse: 19352292.0000\n",
            "Epoch 629/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1631.6494 - mae: 1631.6494 - mse: 19441510.0000 - val_loss: 2056.8374 - val_mae: 2056.8374 - val_mse: 23031056.0000\n",
            "Epoch 630/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1690.7463 - mae: 1690.7463 - mse: 19827832.0000 - val_loss: 1927.9325 - val_mae: 1927.9325 - val_mse: 19425916.0000\n",
            "Epoch 631/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1657.6287 - mae: 1657.6287 - mse: 19395378.0000 - val_loss: 1832.9509 - val_mae: 1832.9509 - val_mse: 21928440.0000\n",
            "Epoch 632/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1669.3149 - mae: 1669.3149 - mse: 19716308.0000 - val_loss: 2357.8545 - val_mae: 2357.8545 - val_mse: 24883066.0000\n",
            "Epoch 633/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1635.4077 - mae: 1635.4077 - mse: 19426574.0000 - val_loss: 2055.7124 - val_mae: 2055.7124 - val_mse: 22829422.0000\n",
            "Epoch 634/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1618.9220 - mae: 1618.9220 - mse: 19324686.0000 - val_loss: 1753.4565 - val_mae: 1753.4565 - val_mse: 19994232.0000\n",
            "Epoch 635/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1665.5752 - mae: 1665.5752 - mse: 19400536.0000 - val_loss: 2297.8186 - val_mae: 2297.8186 - val_mse: 26011098.0000\n",
            "Epoch 636/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1686.7416 - mae: 1686.7416 - mse: 19751012.0000 - val_loss: 1737.0043 - val_mae: 1737.0043 - val_mse: 22420118.0000\n",
            "Epoch 637/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1681.5760 - mae: 1681.5760 - mse: 19806920.0000 - val_loss: 1892.1422 - val_mae: 1892.1422 - val_mse: 19792166.0000\n",
            "Epoch 638/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1644.1919 - mae: 1644.1919 - mse: 19552752.0000 - val_loss: 1694.4232 - val_mae: 1694.4232 - val_mse: 19867902.0000\n",
            "Epoch 639/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1690.1992 - mae: 1690.1992 - mse: 19786162.0000 - val_loss: 1943.0424 - val_mae: 1943.0424 - val_mse: 21668018.0000\n",
            "Epoch 640/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1628.7477 - mae: 1628.7477 - mse: 19463026.0000 - val_loss: 1803.2118 - val_mae: 1803.2118 - val_mse: 19757862.0000\n",
            "Epoch 641/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1614.1248 - mae: 1614.1248 - mse: 19307178.0000 - val_loss: 1813.7557 - val_mae: 1813.7557 - val_mse: 21203674.0000\n",
            "Epoch 642/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1629.7584 - mae: 1629.7584 - mse: 19200662.0000 - val_loss: 2050.9580 - val_mae: 2050.9580 - val_mse: 19715036.0000\n",
            "Epoch 643/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1635.6256 - mae: 1635.6256 - mse: 19441892.0000 - val_loss: 1722.0232 - val_mae: 1722.0232 - val_mse: 20731222.0000\n",
            "Epoch 644/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1645.1959 - mae: 1645.1959 - mse: 19290150.0000 - val_loss: 1712.1554 - val_mae: 1712.1554 - val_mse: 19686622.0000\n",
            "Epoch 645/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1688.6205 - mae: 1688.6205 - mse: 19740544.0000 - val_loss: 1871.2565 - val_mae: 1871.2565 - val_mse: 22817154.0000\n",
            "Epoch 646/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1635.5022 - mae: 1635.5022 - mse: 19445436.0000 - val_loss: 1638.5591 - val_mae: 1638.5591 - val_mse: 20609770.0000\n",
            "Epoch 647/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1638.2152 - mae: 1638.2152 - mse: 19331906.0000 - val_loss: 1701.1707 - val_mae: 1701.1707 - val_mse: 21428530.0000\n",
            "Epoch 648/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1650.8585 - mae: 1650.8585 - mse: 19586242.0000 - val_loss: 1795.9032 - val_mae: 1795.9032 - val_mse: 19421704.0000\n",
            "Epoch 649/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1674.1653 - mae: 1674.1653 - mse: 19800294.0000 - val_loss: 1685.3422 - val_mae: 1685.3422 - val_mse: 20876430.0000\n",
            "Epoch 650/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1656.7599 - mae: 1656.7599 - mse: 19469468.0000 - val_loss: 1771.9050 - val_mae: 1771.9050 - val_mse: 20454048.0000\n",
            "Epoch 651/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1634.9465 - mae: 1634.9465 - mse: 19499844.0000 - val_loss: 1820.1096 - val_mae: 1820.1096 - val_mse: 19411174.0000\n",
            "Epoch 652/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1638.5187 - mae: 1638.5187 - mse: 19319712.0000 - val_loss: 2208.3494 - val_mae: 2208.3494 - val_mse: 20326122.0000\n",
            "Epoch 653/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1652.9990 - mae: 1652.9990 - mse: 19712608.0000 - val_loss: 1791.5282 - val_mae: 1791.5282 - val_mse: 19368938.0000\n",
            "Epoch 654/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1661.6877 - mae: 1661.6877 - mse: 19613980.0000 - val_loss: 1801.2262 - val_mae: 1801.2262 - val_mse: 21837954.0000\n",
            "Epoch 655/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1639.0415 - mae: 1639.0415 - mse: 19399656.0000 - val_loss: 2103.6621 - val_mae: 2103.6621 - val_mse: 20345674.0000\n",
            "Epoch 656/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1690.9156 - mae: 1690.9156 - mse: 19916186.0000 - val_loss: 2095.5442 - val_mae: 2095.5442 - val_mse: 19754056.0000\n",
            "Epoch 657/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1664.7263 - mae: 1664.7263 - mse: 19389932.0000 - val_loss: 2088.3044 - val_mae: 2088.3044 - val_mse: 23180068.0000\n",
            "Epoch 658/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1627.8217 - mae: 1627.8217 - mse: 19441750.0000 - val_loss: 2258.0791 - val_mae: 2258.0791 - val_mse: 25219634.0000\n",
            "Epoch 659/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1654.0194 - mae: 1654.0194 - mse: 19479900.0000 - val_loss: 1749.1615 - val_mae: 1749.1615 - val_mse: 19754616.0000\n",
            "Epoch 660/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1612.1178 - mae: 1612.1178 - mse: 19059230.0000 - val_loss: 1705.8988 - val_mae: 1705.8988 - val_mse: 20063620.0000\n",
            "Epoch 661/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1679.3057 - mae: 1679.3057 - mse: 19745880.0000 - val_loss: 2077.1633 - val_mae: 2077.1633 - val_mse: 23013510.0000\n",
            "Epoch 662/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1607.8452 - mae: 1607.8452 - mse: 19113622.0000 - val_loss: 2235.4236 - val_mae: 2235.4236 - val_mse: 26722826.0000\n",
            "Epoch 663/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1672.6458 - mae: 1672.6458 - mse: 19655628.0000 - val_loss: 1635.1129 - val_mae: 1635.1129 - val_mse: 20605778.0000\n",
            "Epoch 664/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1643.8436 - mae: 1643.8436 - mse: 19696514.0000 - val_loss: 1993.5853 - val_mae: 1993.5853 - val_mse: 21008278.0000\n",
            "Epoch 665/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1638.2786 - mae: 1638.2786 - mse: 19555174.0000 - val_loss: 1781.8397 - val_mae: 1781.8397 - val_mse: 20167168.0000\n",
            "Epoch 666/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1663.8483 - mae: 1663.8483 - mse: 19670880.0000 - val_loss: 1743.6522 - val_mae: 1743.6522 - val_mse: 21141142.0000\n",
            "Epoch 667/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1620.5671 - mae: 1620.5671 - mse: 19216240.0000 - val_loss: 1820.3450 - val_mae: 1820.3450 - val_mse: 20960772.0000\n",
            "Epoch 668/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1673.0105 - mae: 1673.0105 - mse: 19523286.0000 - val_loss: 1730.9518 - val_mae: 1730.9518 - val_mse: 21175398.0000\n",
            "Epoch 669/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1627.9094 - mae: 1627.9094 - mse: 19335128.0000 - val_loss: 1886.2644 - val_mae: 1886.2644 - val_mse: 19691200.0000\n",
            "Epoch 670/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1647.8346 - mae: 1647.8346 - mse: 19279848.0000 - val_loss: 1716.7133 - val_mae: 1716.7133 - val_mse: 20843104.0000\n",
            "Epoch 671/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1657.7217 - mae: 1657.7217 - mse: 19623744.0000 - val_loss: 1886.1018 - val_mae: 1886.1018 - val_mse: 19534414.0000\n",
            "Epoch 672/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1669.7306 - mae: 1669.7306 - mse: 19805164.0000 - val_loss: 1935.3534 - val_mae: 1935.3534 - val_mse: 22231160.0000\n",
            "Epoch 673/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1660.3735 - mae: 1660.3735 - mse: 19501966.0000 - val_loss: 1916.4031 - val_mae: 1916.4031 - val_mse: 19442904.0000\n",
            "Epoch 674/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1640.9269 - mae: 1640.9269 - mse: 19565356.0000 - val_loss: 1744.2748 - val_mae: 1744.2748 - val_mse: 19775480.0000\n",
            "Epoch 675/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1645.1702 - mae: 1645.1702 - mse: 19373076.0000 - val_loss: 1659.5858 - val_mae: 1659.5858 - val_mse: 20967270.0000\n",
            "Epoch 676/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.8550 - mae: 1603.8550 - mse: 19318904.0000 - val_loss: 1801.0715 - val_mae: 1801.0715 - val_mse: 21550320.0000\n",
            "Epoch 677/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1627.2598 - mae: 1627.2598 - mse: 19485108.0000 - val_loss: 1684.7646 - val_mae: 1684.7646 - val_mse: 19728054.0000\n",
            "Epoch 678/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1645.9650 - mae: 1645.9650 - mse: 19143392.0000 - val_loss: 1858.6262 - val_mae: 1858.6262 - val_mse: 22158508.0000\n",
            "Epoch 679/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1624.2877 - mae: 1624.2877 - mse: 19132268.0000 - val_loss: 1704.8451 - val_mae: 1704.8451 - val_mse: 20807274.0000\n",
            "Epoch 680/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1647.0321 - mae: 1647.0321 - mse: 19285944.0000 - val_loss: 1808.7196 - val_mae: 1808.7196 - val_mse: 20173466.0000\n",
            "Epoch 681/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.3683 - mae: 1588.3683 - mse: 18993760.0000 - val_loss: 1815.4656 - val_mae: 1815.4656 - val_mse: 21049638.0000\n",
            "Epoch 682/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1624.3257 - mae: 1624.3257 - mse: 19058266.0000 - val_loss: 1809.1423 - val_mae: 1809.1423 - val_mse: 19917912.0000\n",
            "Epoch 683/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1661.1576 - mae: 1661.1576 - mse: 19318572.0000 - val_loss: 2057.3799 - val_mae: 2057.3799 - val_mse: 19433416.0000\n",
            "Epoch 684/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1619.3312 - mae: 1619.3312 - mse: 19079306.0000 - val_loss: 1789.0784 - val_mae: 1789.0784 - val_mse: 21889594.0000\n",
            "Epoch 685/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1637.9323 - mae: 1637.9323 - mse: 19561396.0000 - val_loss: 1676.4545 - val_mae: 1676.4545 - val_mse: 21418410.0000\n",
            "Epoch 686/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1627.1190 - mae: 1627.1190 - mse: 19476820.0000 - val_loss: 1828.2360 - val_mae: 1828.2360 - val_mse: 21570014.0000\n",
            "Epoch 687/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.3477 - mae: 1588.3477 - mse: 19042864.0000 - val_loss: 2079.6694 - val_mae: 2079.6694 - val_mse: 19603300.0000\n",
            "Epoch 688/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1638.8894 - mae: 1638.8894 - mse: 19388406.0000 - val_loss: 1829.5682 - val_mae: 1829.5682 - val_mse: 19615450.0000\n",
            "Epoch 689/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1634.3506 - mae: 1634.3506 - mse: 19512854.0000 - val_loss: 1907.9933 - val_mae: 1907.9933 - val_mse: 19568396.0000\n",
            "Epoch 690/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1618.7010 - mae: 1618.7010 - mse: 19258690.0000 - val_loss: 2185.2500 - val_mae: 2185.2500 - val_mse: 23131920.0000\n",
            "Epoch 691/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1656.3004 - mae: 1656.3004 - mse: 19597096.0000 - val_loss: 1826.5802 - val_mae: 1826.5802 - val_mse: 21568330.0000\n",
            "Epoch 692/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1609.5708 - mae: 1609.5708 - mse: 19239824.0000 - val_loss: 1692.4241 - val_mae: 1692.4241 - val_mse: 19519216.0000\n",
            "Epoch 693/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1623.1608 - mae: 1623.1608 - mse: 19199190.0000 - val_loss: 1772.1375 - val_mae: 1772.1375 - val_mse: 19456582.0000\n",
            "Epoch 694/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1634.6414 - mae: 1634.6414 - mse: 19380664.0000 - val_loss: 1674.5239 - val_mae: 1674.5239 - val_mse: 20714652.0000\n",
            "Epoch 695/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1633.8973 - mae: 1633.8973 - mse: 19359008.0000 - val_loss: 1952.4117 - val_mae: 1952.4117 - val_mse: 22346434.0000\n",
            "Epoch 696/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1631.4679 - mae: 1631.4679 - mse: 19408788.0000 - val_loss: 1714.6266 - val_mae: 1714.6266 - val_mse: 20568560.0000\n",
            "Epoch 697/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1627.6219 - mae: 1627.6219 - mse: 19140344.0000 - val_loss: 1620.0637 - val_mae: 1620.0637 - val_mse: 20524410.0000\n",
            "Epoch 698/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1620.6370 - mae: 1620.6370 - mse: 19193364.0000 - val_loss: 1683.1508 - val_mae: 1683.1508 - val_mse: 19478296.0000\n",
            "Epoch 699/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1619.0315 - mae: 1619.0315 - mse: 19468906.0000 - val_loss: 2009.4060 - val_mae: 2009.4060 - val_mse: 22639588.0000\n",
            "Epoch 700/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1634.4214 - mae: 1634.4214 - mse: 19394314.0000 - val_loss: 1819.6672 - val_mae: 1819.6672 - val_mse: 21359786.0000\n",
            "Epoch 701/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1600.0769 - mae: 1600.0769 - mse: 19230998.0000 - val_loss: 1664.1664 - val_mae: 1664.1664 - val_mse: 20227740.0000\n",
            "Epoch 702/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1659.6077 - mae: 1659.6077 - mse: 19427934.0000 - val_loss: 1730.5215 - val_mae: 1730.5215 - val_mse: 21357218.0000\n",
            "Epoch 703/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1601.4668 - mae: 1601.4668 - mse: 19607848.0000 - val_loss: 1918.2072 - val_mae: 1918.2072 - val_mse: 21411628.0000\n",
            "Epoch 704/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1597.8823 - mae: 1597.8823 - mse: 19100266.0000 - val_loss: 1595.0972 - val_mae: 1595.0972 - val_mse: 20298074.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 705/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1585.1334 - mae: 1585.1334 - mse: 18948214.0000 - val_loss: 1889.1094 - val_mae: 1889.1094 - val_mse: 21466004.0000\n",
            "Epoch 706/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1635.5468 - mae: 1635.5468 - mse: 19435484.0000 - val_loss: 1682.9901 - val_mae: 1682.9901 - val_mse: 20309418.0000\n",
            "Epoch 707/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1633.1631 - mae: 1633.1631 - mse: 19628610.0000 - val_loss: 1823.2205 - val_mae: 1823.2205 - val_mse: 19803018.0000\n",
            "Epoch 708/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1653.2848 - mae: 1653.2848 - mse: 19595486.0000 - val_loss: 1898.8145 - val_mae: 1898.8145 - val_mse: 19802580.0000\n",
            "Epoch 709/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1569.9547 - mae: 1569.9547 - mse: 18679902.0000 - val_loss: 2064.9690 - val_mae: 2064.9690 - val_mse: 19732380.0000\n",
            "Epoch 710/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1627.3031 - mae: 1627.3031 - mse: 19345486.0000 - val_loss: 1960.2598 - val_mae: 1960.2598 - val_mse: 22121582.0000\n",
            "Epoch 711/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1607.8689 - mae: 1607.8689 - mse: 19398388.0000 - val_loss: 1843.2041 - val_mae: 1843.2041 - val_mse: 19323208.0000\n",
            "Epoch 712/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1637.4861 - mae: 1637.4861 - mse: 19530706.0000 - val_loss: 2070.2205 - val_mae: 2070.2205 - val_mse: 23331722.0000\n",
            "Epoch 713/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1612.9514 - mae: 1612.9514 - mse: 19376422.0000 - val_loss: 1897.8639 - val_mae: 1897.8639 - val_mse: 19584332.0000\n",
            "Epoch 714/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1621.1841 - mae: 1621.1841 - mse: 19201678.0000 - val_loss: 1972.9285 - val_mae: 1972.9285 - val_mse: 22671750.0000\n",
            "Epoch 715/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1663.8176 - mae: 1663.8176 - mse: 19809508.0000 - val_loss: 1848.9895 - val_mae: 1848.9895 - val_mse: 21834156.0000\n",
            "Epoch 716/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1597.6887 - mae: 1597.6887 - mse: 18792262.0000 - val_loss: 2184.4822 - val_mae: 2184.4822 - val_mse: 23985656.0000\n",
            "Epoch 717/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1618.3907 - mae: 1618.3907 - mse: 19227416.0000 - val_loss: 1708.5717 - val_mae: 1708.5717 - val_mse: 21104954.0000\n",
            "Epoch 718/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.1066 - mae: 1603.1066 - mse: 19352660.0000 - val_loss: 1697.7579 - val_mae: 1697.7579 - val_mse: 20960434.0000\n",
            "Epoch 719/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1635.5624 - mae: 1635.5624 - mse: 19316502.0000 - val_loss: 1924.4889 - val_mae: 1924.4889 - val_mse: 20576980.0000\n",
            "Epoch 720/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1636.2473 - mae: 1636.2473 - mse: 19372552.0000 - val_loss: 1627.2479 - val_mae: 1627.2479 - val_mse: 20698356.0000\n",
            "Epoch 721/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.0232 - mae: 1603.0232 - mse: 19030148.0000 - val_loss: 1900.5922 - val_mae: 1900.5922 - val_mse: 19833172.0000\n",
            "Epoch 722/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.8582 - mae: 1603.8582 - mse: 18706226.0000 - val_loss: 1654.4377 - val_mae: 1654.4377 - val_mse: 20013608.0000\n",
            "Epoch 723/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1637.2625 - mae: 1637.2625 - mse: 19361920.0000 - val_loss: 1648.2294 - val_mae: 1648.2294 - val_mse: 20791492.0000\n",
            "Epoch 724/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1647.6316 - mae: 1647.6316 - mse: 19387788.0000 - val_loss: 1642.2524 - val_mae: 1642.2524 - val_mse: 19902500.0000\n",
            "Epoch 725/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1605.7112 - mae: 1605.7112 - mse: 19255000.0000 - val_loss: 2074.9160 - val_mae: 2074.9160 - val_mse: 19831734.0000\n",
            "Epoch 726/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1608.7516 - mae: 1608.7516 - mse: 19275848.0000 - val_loss: 1900.2358 - val_mae: 1900.2358 - val_mse: 19831300.0000\n",
            "Epoch 727/1000\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1640.0270 - mae: 1640.0270 - mse: 19416212.0000 - val_loss: 1946.1404 - val_mae: 1946.1404 - val_mse: 23911026.0000\n",
            "Epoch 728/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1614.3154 - mae: 1614.3154 - mse: 19342840.0000 - val_loss: 1623.6440 - val_mae: 1623.6440 - val_mse: 20644476.0000\n",
            "Epoch 729/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1607.1483 - mae: 1607.1483 - mse: 19449070.0000 - val_loss: 1675.2781 - val_mae: 1675.2781 - val_mse: 21510366.0000\n",
            "Epoch 730/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1612.7977 - mae: 1612.7977 - mse: 19335598.0000 - val_loss: 1918.8503 - val_mae: 1918.8503 - val_mse: 23130120.0000\n",
            "Epoch 731/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1659.1598 - mae: 1659.1598 - mse: 19702496.0000 - val_loss: 2054.9443 - val_mae: 2054.9443 - val_mse: 22530012.0000\n",
            "Epoch 732/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1613.7015 - mae: 1613.7015 - mse: 19314298.0000 - val_loss: 1763.6318 - val_mae: 1763.6318 - val_mse: 19517774.0000\n",
            "Epoch 733/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1612.9192 - mae: 1612.9192 - mse: 19485548.0000 - val_loss: 1762.8519 - val_mae: 1762.8519 - val_mse: 19445008.0000\n",
            "Epoch 734/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.1578 - mae: 1593.1578 - mse: 19331600.0000 - val_loss: 2289.2930 - val_mae: 2289.2930 - val_mse: 20854484.0000\n",
            "Epoch 735/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1625.1384 - mae: 1625.1384 - mse: 19038746.0000 - val_loss: 1578.3511 - val_mae: 1578.3511 - val_mse: 20243468.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 736/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1644.1118 - mae: 1644.1118 - mse: 19366506.0000 - val_loss: 1782.4067 - val_mae: 1782.4067 - val_mse: 21483960.0000\n",
            "Epoch 737/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1613.0273 - mae: 1613.0273 - mse: 19228772.0000 - val_loss: 1625.0933 - val_mae: 1625.0933 - val_mse: 20621870.0000\n",
            "Epoch 738/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1588.1428 - mae: 1588.1428 - mse: 19284820.0000 - val_loss: 1664.1162 - val_mae: 1664.1162 - val_mse: 20577186.0000\n",
            "Epoch 739/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1627.8455 - mae: 1627.8455 - mse: 19169480.0000 - val_loss: 1609.0795 - val_mae: 1609.0795 - val_mse: 19938152.0000\n",
            "Epoch 740/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.7188 - mae: 1605.7188 - mse: 19245980.0000 - val_loss: 1836.7656 - val_mae: 1836.7656 - val_mse: 21978060.0000\n",
            "Epoch 741/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1650.4470 - mae: 1650.4470 - mse: 19344786.0000 - val_loss: 1724.7183 - val_mae: 1724.7183 - val_mse: 19529838.0000\n",
            "Epoch 742/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1641.0692 - mae: 1641.0692 - mse: 19305054.0000 - val_loss: 1788.2589 - val_mae: 1788.2589 - val_mse: 21515766.0000\n",
            "Epoch 743/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1583.2755 - mae: 1583.2755 - mse: 19286880.0000 - val_loss: 1644.1854 - val_mae: 1644.1854 - val_mse: 20866914.0000\n",
            "Epoch 744/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1624.6205 - mae: 1624.6205 - mse: 19223658.0000 - val_loss: 1569.4644 - val_mae: 1569.4644 - val_mse: 20336520.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 745/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.9009 - mae: 1603.9009 - mse: 19096858.0000 - val_loss: 1829.6169 - val_mae: 1829.6169 - val_mse: 19839678.0000\n",
            "Epoch 746/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1587.3617 - mae: 1587.3617 - mse: 19172332.0000 - val_loss: 1758.5485 - val_mae: 1758.5485 - val_mse: 21002130.0000\n",
            "Epoch 747/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1639.3170 - mae: 1639.3170 - mse: 19342332.0000 - val_loss: 1820.0236 - val_mae: 1820.0236 - val_mse: 21482090.0000\n",
            "Epoch 748/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1603.2321 - mae: 1603.2321 - mse: 19097766.0000 - val_loss: 1764.0166 - val_mae: 1764.0166 - val_mse: 19471980.0000\n",
            "Epoch 749/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1630.4474 - mae: 1630.4474 - mse: 19286880.0000 - val_loss: 1572.0627 - val_mae: 1572.0627 - val_mse: 19839794.0000\n",
            "Epoch 750/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1602.1036 - mae: 1602.1036 - mse: 19187598.0000 - val_loss: 1725.9545 - val_mae: 1725.9545 - val_mse: 20365912.0000\n",
            "Epoch 751/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1619.6748 - mae: 1619.6748 - mse: 19449180.0000 - val_loss: 1792.1903 - val_mae: 1792.1903 - val_mse: 21312156.0000\n",
            "Epoch 752/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1606.5239 - mae: 1606.5239 - mse: 19293784.0000 - val_loss: 1797.8160 - val_mae: 1797.8160 - val_mse: 20594506.0000\n",
            "Epoch 753/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1579.0706 - mae: 1579.0706 - mse: 19120928.0000 - val_loss: 2103.7400 - val_mae: 2103.7400 - val_mse: 19716154.0000\n",
            "Epoch 754/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1629.6681 - mae: 1629.6681 - mse: 19455162.0000 - val_loss: 1692.1685 - val_mae: 1692.1685 - val_mse: 19744122.0000\n",
            "Epoch 755/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1617.2650 - mae: 1617.2650 - mse: 19149410.0000 - val_loss: 1826.0306 - val_mae: 1826.0306 - val_mse: 19286294.0000\n",
            "Epoch 756/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1636.8976 - mae: 1636.8976 - mse: 19700210.0000 - val_loss: 1665.3264 - val_mae: 1665.3264 - val_mse: 19904390.0000\n",
            "Epoch 757/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1591.2540 - mae: 1591.2540 - mse: 19047956.0000 - val_loss: 1707.8251 - val_mae: 1707.8251 - val_mse: 20855044.0000\n",
            "Epoch 758/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1620.2279 - mae: 1620.2279 - mse: 19168910.0000 - val_loss: 1715.8922 - val_mae: 1715.8922 - val_mse: 19537234.0000\n",
            "Epoch 759/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1571.8423 - mae: 1571.8423 - mse: 19158202.0000 - val_loss: 2347.5647 - val_mae: 2347.5647 - val_mse: 24984048.0000\n",
            "Epoch 760/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1654.4070 - mae: 1654.4070 - mse: 19696260.0000 - val_loss: 1647.4799 - val_mae: 1647.4799 - val_mse: 20682362.0000\n",
            "Epoch 761/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1586.4939 - mae: 1586.4939 - mse: 18868282.0000 - val_loss: 1650.8499 - val_mae: 1650.8499 - val_mse: 20755322.0000\n",
            "Epoch 762/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1606.2023 - mae: 1606.2023 - mse: 18830264.0000 - val_loss: 1563.6376 - val_mae: 1563.6376 - val_mse: 19861060.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 763/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1617.3020 - mae: 1617.3020 - mse: 19127068.0000 - val_loss: 1914.5856 - val_mae: 1914.5856 - val_mse: 22183572.0000\n",
            "Epoch 764/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1599.2754 - mae: 1599.2754 - mse: 19372650.0000 - val_loss: 1600.2263 - val_mae: 1600.2263 - val_mse: 20407882.0000\n",
            "Epoch 765/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1575.3982 - mae: 1575.3982 - mse: 18877768.0000 - val_loss: 2166.8521 - val_mae: 2166.8521 - val_mse: 23130290.0000\n",
            "Epoch 766/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1613.1006 - mae: 1613.1006 - mse: 19213464.0000 - val_loss: 1841.7085 - val_mae: 1841.7085 - val_mse: 21553154.0000\n",
            "Epoch 767/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1597.4548 - mae: 1597.4548 - mse: 19257628.0000 - val_loss: 1994.0677 - val_mae: 1994.0677 - val_mse: 19320974.0000\n",
            "Epoch 768/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1625.0448 - mae: 1625.0448 - mse: 19464548.0000 - val_loss: 1753.1053 - val_mae: 1753.1053 - val_mse: 19654310.0000\n",
            "Epoch 769/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1597.4077 - mae: 1597.4077 - mse: 19315464.0000 - val_loss: 1775.9972 - val_mae: 1775.9972 - val_mse: 21321562.0000\n",
            "Epoch 770/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1601.5322 - mae: 1601.5322 - mse: 19434078.0000 - val_loss: 1688.0468 - val_mae: 1688.0468 - val_mse: 19838328.0000\n",
            "Epoch 771/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1596.4430 - mae: 1596.4430 - mse: 19142936.0000 - val_loss: 1554.5193 - val_mae: 1554.5193 - val_mse: 19847862.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 772/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1571.3528 - mae: 1571.3528 - mse: 19183426.0000 - val_loss: 1894.2000 - val_mae: 1894.2000 - val_mse: 19624736.0000\n",
            "Epoch 773/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1578.6221 - mae: 1578.6219 - mse: 19007650.0000 - val_loss: 1693.0500 - val_mae: 1693.0500 - val_mse: 20312922.0000\n",
            "Epoch 774/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1628.8735 - mae: 1628.8735 - mse: 19552662.0000 - val_loss: 2230.3843 - val_mae: 2230.3843 - val_mse: 24092384.0000\n",
            "Epoch 775/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1608.1125 - mae: 1608.1125 - mse: 19253204.0000 - val_loss: 1656.2471 - val_mae: 1656.2471 - val_mse: 19615672.0000\n",
            "Epoch 776/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1574.9132 - mae: 1574.9132 - mse: 18891728.0000 - val_loss: 1894.3557 - val_mae: 1894.3557 - val_mse: 22271284.0000\n",
            "Epoch 777/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.3202 - mae: 1616.3202 - mse: 19336446.0000 - val_loss: 1768.3613 - val_mae: 1768.3613 - val_mse: 21113214.0000\n",
            "Epoch 778/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1574.5924 - mae: 1574.5924 - mse: 19069176.0000 - val_loss: 1639.3640 - val_mae: 1639.3640 - val_mse: 20638084.0000\n",
            "Epoch 779/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1592.7960 - mae: 1592.7960 - mse: 19281002.0000 - val_loss: 1641.0839 - val_mae: 1641.0839 - val_mse: 19808552.0000\n",
            "Epoch 780/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1603.9437 - mae: 1603.9437 - mse: 19363550.0000 - val_loss: 1776.1481 - val_mae: 1776.1481 - val_mse: 21448768.0000\n",
            "Epoch 781/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1600.9315 - mae: 1600.9315 - mse: 19203940.0000 - val_loss: 1767.5497 - val_mae: 1767.5497 - val_mse: 19592572.0000\n",
            "Epoch 782/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1597.6862 - mae: 1597.6862 - mse: 19254288.0000 - val_loss: 1686.1840 - val_mae: 1686.1840 - val_mse: 21439264.0000\n",
            "Epoch 783/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1624.2144 - mae: 1624.2144 - mse: 19325254.0000 - val_loss: 1583.1304 - val_mae: 1583.1304 - val_mse: 19633202.0000\n",
            "Epoch 784/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.5378 - mae: 1605.5378 - mse: 19541282.0000 - val_loss: 1610.3534 - val_mae: 1610.3534 - val_mse: 19517858.0000\n",
            "Epoch 785/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1603.3804 - mae: 1603.3804 - mse: 18996678.0000 - val_loss: 1688.6733 - val_mae: 1688.6733 - val_mse: 19649228.0000\n",
            "Epoch 786/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1608.9022 - mae: 1608.9022 - mse: 19454880.0000 - val_loss: 1693.5640 - val_mae: 1693.5640 - val_mse: 20769914.0000\n",
            "Epoch 787/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1630.3026 - mae: 1630.3026 - mse: 19554880.0000 - val_loss: 1696.6255 - val_mae: 1696.6255 - val_mse: 21017954.0000\n",
            "Epoch 788/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1601.2128 - mae: 1601.2128 - mse: 19206812.0000 - val_loss: 1767.5906 - val_mae: 1767.5906 - val_mse: 21079580.0000\n",
            "Epoch 789/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1564.2759 - mae: 1564.2759 - mse: 18898984.0000 - val_loss: 1648.9972 - val_mae: 1648.9972 - val_mse: 21057470.0000\n",
            "Epoch 790/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1590.6637 - mae: 1590.6637 - mse: 19326070.0000 - val_loss: 1611.8607 - val_mae: 1611.8607 - val_mse: 19605370.0000\n",
            "Epoch 791/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1591.5273 - mae: 1591.5273 - mse: 19315848.0000 - val_loss: 1689.2494 - val_mae: 1689.2494 - val_mse: 20566630.0000\n",
            "Epoch 792/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1598.6627 - mae: 1598.6627 - mse: 19163460.0000 - val_loss: 1772.0610 - val_mae: 1772.0610 - val_mse: 21292532.0000\n",
            "Epoch 793/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1579.3312 - mae: 1579.3312 - mse: 18935764.0000 - val_loss: 1711.5488 - val_mae: 1711.5488 - val_mse: 19561864.0000\n",
            "Epoch 794/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1612.5164 - mae: 1612.5164 - mse: 19431396.0000 - val_loss: 1577.6438 - val_mae: 1577.6438 - val_mse: 20117044.0000\n",
            "Epoch 795/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.3149 - mae: 1593.3149 - mse: 19305196.0000 - val_loss: 1592.8510 - val_mae: 1592.8510 - val_mse: 20170162.0000\n",
            "Epoch 796/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1585.0199 - mae: 1585.0199 - mse: 19302960.0000 - val_loss: 1744.1265 - val_mae: 1744.1265 - val_mse: 21165044.0000\n",
            "Epoch 797/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1579.3005 - mae: 1579.3005 - mse: 19249622.0000 - val_loss: 1799.6345 - val_mae: 1799.6345 - val_mse: 21422784.0000\n",
            "Epoch 798/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1583.6027 - mae: 1583.6027 - mse: 18886734.0000 - val_loss: 1750.0433 - val_mae: 1750.0433 - val_mse: 21198092.0000\n",
            "Epoch 799/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1576.6725 - mae: 1576.6725 - mse: 18857610.0000 - val_loss: 1662.3859 - val_mae: 1662.3859 - val_mse: 20506424.0000\n",
            "Epoch 800/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1598.0723 - mae: 1598.0723 - mse: 19249324.0000 - val_loss: 1752.9167 - val_mae: 1752.9167 - val_mse: 21421436.0000\n",
            "Epoch 801/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1596.7744 - mae: 1596.7744 - mse: 19144592.0000 - val_loss: 1581.6769 - val_mae: 1581.6769 - val_mse: 20066040.0000\n",
            "Epoch 802/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1562.2859 - mae: 1562.2859 - mse: 18870990.0000 - val_loss: 1800.9266 - val_mae: 1800.9266 - val_mse: 19630290.0000\n",
            "Epoch 803/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1608.6766 - mae: 1608.6766 - mse: 19073442.0000 - val_loss: 1639.1389 - val_mae: 1639.1389 - val_mse: 19742906.0000\n",
            "Epoch 804/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1578.1216 - mae: 1578.1216 - mse: 19164920.0000 - val_loss: 1920.2284 - val_mae: 1920.2284 - val_mse: 22096870.0000\n",
            "Epoch 805/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.8488 - mae: 1616.8488 - mse: 19342734.0000 - val_loss: 1736.9708 - val_mae: 1736.9708 - val_mse: 19625278.0000\n",
            "Epoch 806/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1591.5913 - mae: 1591.5913 - mse: 19177734.0000 - val_loss: 1909.4092 - val_mae: 1909.4092 - val_mse: 22298896.0000\n",
            "Epoch 807/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1587.2903 - mae: 1587.2903 - mse: 19034364.0000 - val_loss: 1743.8016 - val_mae: 1743.8016 - val_mse: 21234992.0000\n",
            "Epoch 808/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1590.9023 - mae: 1590.9023 - mse: 18960072.0000 - val_loss: 1763.2618 - val_mae: 1763.2618 - val_mse: 20304992.0000\n",
            "Epoch 809/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1610.7882 - mae: 1610.7882 - mse: 19043082.0000 - val_loss: 1956.7257 - val_mae: 1956.7257 - val_mse: 22804990.0000\n",
            "Epoch 810/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1545.7435 - mae: 1545.7435 - mse: 18971398.0000 - val_loss: 1829.1617 - val_mae: 1829.1617 - val_mse: 19381952.0000\n",
            "Epoch 811/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1600.3108 - mae: 1600.3108 - mse: 19033248.0000 - val_loss: 2030.9479 - val_mae: 2030.9479 - val_mse: 19370210.0000\n",
            "Epoch 812/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.4496 - mae: 1605.4496 - mse: 19264734.0000 - val_loss: 1943.5868 - val_mae: 1943.5868 - val_mse: 22096480.0000\n",
            "Epoch 813/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1602.2264 - mae: 1602.2264 - mse: 19396038.0000 - val_loss: 1651.1063 - val_mae: 1651.1063 - val_mse: 19951936.0000\n",
            "Epoch 814/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1565.1467 - mae: 1565.1467 - mse: 19050366.0000 - val_loss: 1608.4851 - val_mae: 1608.4851 - val_mse: 20391048.0000\n",
            "Epoch 815/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.9432 - mae: 1605.9432 - mse: 19094490.0000 - val_loss: 1766.8282 - val_mae: 1766.8282 - val_mse: 19488272.0000\n",
            "Epoch 816/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1586.0940 - mae: 1586.0940 - mse: 19133674.0000 - val_loss: 1573.9873 - val_mae: 1573.9873 - val_mse: 20245012.0000\n",
            "Epoch 817/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1581.5223 - mae: 1581.5223 - mse: 19536158.0000 - val_loss: 1812.4388 - val_mae: 1812.4388 - val_mse: 19664516.0000\n",
            "Epoch 818/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1590.9241 - mae: 1590.9241 - mse: 19004680.0000 - val_loss: 1930.9113 - val_mae: 1930.9113 - val_mse: 20094770.0000\n",
            "Epoch 819/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1607.7753 - mae: 1607.7753 - mse: 19404544.0000 - val_loss: 1972.8408 - val_mae: 1972.8408 - val_mse: 19729020.0000\n",
            "Epoch 820/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1584.5996 - mae: 1584.5996 - mse: 18929272.0000 - val_loss: 1671.1869 - val_mae: 1671.1869 - val_mse: 19861640.0000\n",
            "Epoch 821/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1581.2274 - mae: 1581.2274 - mse: 19084082.0000 - val_loss: 1829.2349 - val_mae: 1829.2349 - val_mse: 19692144.0000\n",
            "Epoch 822/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.3153 - mae: 1616.3153 - mse: 19055240.0000 - val_loss: 1595.0291 - val_mae: 1595.0291 - val_mse: 20603058.0000\n",
            "Epoch 823/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1569.7485 - mae: 1569.7485 - mse: 19587416.0000 - val_loss: 1578.3688 - val_mae: 1578.3688 - val_mse: 20270532.0000\n",
            "Epoch 824/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1552.3417 - mae: 1552.3417 - mse: 19197768.0000 - val_loss: 1587.6384 - val_mae: 1587.6384 - val_mse: 20134018.0000\n",
            "Epoch 825/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1602.2937 - mae: 1602.2937 - mse: 19446232.0000 - val_loss: 1593.8364 - val_mae: 1593.8364 - val_mse: 19757938.0000\n",
            "Epoch 826/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.8097 - mae: 1605.8097 - mse: 19281312.0000 - val_loss: 1593.5634 - val_mae: 1593.5634 - val_mse: 20395420.0000\n",
            "Epoch 827/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1593.8975 - mae: 1593.8975 - mse: 19307788.0000 - val_loss: 1736.1501 - val_mae: 1736.1501 - val_mse: 21526752.0000\n",
            "Epoch 828/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1568.7970 - mae: 1568.7970 - mse: 18992370.0000 - val_loss: 1759.1647 - val_mae: 1759.1647 - val_mse: 21172650.0000\n",
            "Epoch 829/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1604.7319 - mae: 1604.7319 - mse: 19242696.0000 - val_loss: 1814.6615 - val_mae: 1814.6615 - val_mse: 21341868.0000\n",
            "Epoch 830/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1551.0201 - mae: 1551.0201 - mse: 18737558.0000 - val_loss: 1844.6528 - val_mae: 1844.6528 - val_mse: 19635776.0000\n",
            "Epoch 831/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1572.0958 - mae: 1572.0958 - mse: 18895222.0000 - val_loss: 1593.6161 - val_mae: 1593.6161 - val_mse: 20661746.0000\n",
            "Epoch 832/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1614.3019 - mae: 1614.3019 - mse: 19234382.0000 - val_loss: 1885.8331 - val_mae: 1885.8331 - val_mse: 21566200.0000\n",
            "Epoch 833/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1596.5341 - mae: 1596.5341 - mse: 19350946.0000 - val_loss: 1713.0181 - val_mae: 1713.0181 - val_mse: 19542396.0000\n",
            "Epoch 834/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1591.0911 - mae: 1591.0911 - mse: 19089034.0000 - val_loss: 1670.3770 - val_mae: 1670.3770 - val_mse: 20635596.0000\n",
            "Epoch 835/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1569.8615 - mae: 1569.8615 - mse: 19603632.0000 - val_loss: 1979.6155 - val_mae: 1979.6155 - val_mse: 19406292.0000\n",
            "Epoch 836/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1578.1891 - mae: 1578.1891 - mse: 19005390.0000 - val_loss: 1705.4841 - val_mae: 1705.4841 - val_mse: 21641738.0000\n",
            "Epoch 837/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1589.2909 - mae: 1589.2909 - mse: 19032200.0000 - val_loss: 1588.5815 - val_mae: 1588.5815 - val_mse: 20444974.0000\n",
            "Epoch 838/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1593.5038 - mae: 1593.5038 - mse: 19171154.0000 - val_loss: 1718.8416 - val_mae: 1718.8416 - val_mse: 20006078.0000\n",
            "Epoch 839/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1606.4821 - mae: 1606.4821 - mse: 19473600.0000 - val_loss: 1573.8807 - val_mae: 1573.8807 - val_mse: 20113664.0000\n",
            "Epoch 840/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1578.4039 - mae: 1578.4039 - mse: 19234736.0000 - val_loss: 1666.7269 - val_mae: 1666.7269 - val_mse: 19901896.0000\n",
            "Epoch 841/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1606.5187 - mae: 1606.5187 - mse: 19238198.0000 - val_loss: 1572.7908 - val_mae: 1572.7908 - val_mse: 20197008.0000\n",
            "Epoch 842/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1580.5870 - mae: 1580.5869 - mse: 19118614.0000 - val_loss: 1638.7877 - val_mae: 1638.7877 - val_mse: 20852996.0000\n",
            "Epoch 843/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1578.9606 - mae: 1578.9606 - mse: 18994752.0000 - val_loss: 1775.2867 - val_mae: 1775.2867 - val_mse: 19842912.0000\n",
            "Epoch 844/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1555.4117 - mae: 1555.4117 - mse: 18941950.0000 - val_loss: 1822.8624 - val_mae: 1822.8624 - val_mse: 21752846.0000\n",
            "Epoch 845/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1579.4257 - mae: 1579.4257 - mse: 18693272.0000 - val_loss: 1883.0516 - val_mae: 1883.0516 - val_mse: 21993996.0000\n",
            "Epoch 846/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1588.0521 - mae: 1588.0521 - mse: 19245206.0000 - val_loss: 1648.1469 - val_mae: 1648.1469 - val_mse: 20604748.0000\n",
            "Epoch 847/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1576.5023 - mae: 1576.5023 - mse: 18961020.0000 - val_loss: 1676.6860 - val_mae: 1676.6860 - val_mse: 21705116.0000\n",
            "Epoch 848/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1584.9537 - mae: 1584.9537 - mse: 19001846.0000 - val_loss: 1935.3301 - val_mae: 1935.3301 - val_mse: 22671784.0000\n",
            "Epoch 849/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1568.2501 - mae: 1568.2501 - mse: 19087076.0000 - val_loss: 1926.8051 - val_mae: 1926.8051 - val_mse: 20110240.0000\n",
            "Epoch 850/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1595.7416 - mae: 1595.7416 - mse: 19270088.0000 - val_loss: 1780.7709 - val_mae: 1780.7709 - val_mse: 20748922.0000\n",
            "Epoch 851/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1582.1503 - mae: 1582.1503 - mse: 18979558.0000 - val_loss: 1806.5424 - val_mae: 1806.5424 - val_mse: 22472666.0000\n",
            "Epoch 852/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1564.6517 - mae: 1564.6517 - mse: 18896192.0000 - val_loss: 1970.3282 - val_mae: 1970.3282 - val_mse: 22450724.0000\n",
            "Epoch 853/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1589.8154 - mae: 1589.8154 - mse: 19176200.0000 - val_loss: 1661.2924 - val_mae: 1661.2924 - val_mse: 20816918.0000\n",
            "Epoch 854/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1591.5564 - mae: 1591.5564 - mse: 19294860.0000 - val_loss: 1702.2167 - val_mae: 1702.2167 - val_mse: 19741014.0000\n",
            "Epoch 855/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1558.5282 - mae: 1558.5282 - mse: 18898798.0000 - val_loss: 1717.5604 - val_mae: 1717.5604 - val_mse: 21047044.0000\n",
            "Epoch 856/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1589.1173 - mae: 1589.1173 - mse: 19151212.0000 - val_loss: 1737.5720 - val_mae: 1737.5720 - val_mse: 19445898.0000\n",
            "Epoch 857/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1555.0187 - mae: 1555.0187 - mse: 18843144.0000 - val_loss: 1560.6851 - val_mae: 1560.6851 - val_mse: 20639422.0000\n",
            "Epoch 858/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1581.5997 - mae: 1581.5997 - mse: 18972258.0000 - val_loss: 1736.3451 - val_mae: 1736.3451 - val_mse: 19979936.0000\n",
            "Epoch 859/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1567.1538 - mae: 1567.1538 - mse: 19021418.0000 - val_loss: 1555.2852 - val_mae: 1555.2852 - val_mse: 20405496.0000\n",
            "Epoch 860/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1572.7506 - mae: 1572.7506 - mse: 18789166.0000 - val_loss: 1790.8912 - val_mae: 1790.8912 - val_mse: 21014676.0000\n",
            "Epoch 861/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1616.2825 - mae: 1616.2825 - mse: 19273616.0000 - val_loss: 1778.3459 - val_mae: 1778.3459 - val_mse: 21439736.0000\n",
            "Epoch 862/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1567.4879 - mae: 1567.4879 - mse: 18928522.0000 - val_loss: 1681.7686 - val_mae: 1681.7686 - val_mse: 21060342.0000\n",
            "Epoch 863/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1580.8004 - mae: 1580.8004 - mse: 19071640.0000 - val_loss: 1692.3601 - val_mae: 1692.3601 - val_mse: 21079428.0000\n",
            "Epoch 864/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1598.1942 - mae: 1598.1942 - mse: 19359200.0000 - val_loss: 1903.2433 - val_mae: 1903.2433 - val_mse: 22000538.0000\n",
            "Epoch 865/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1524.8630 - mae: 1524.8630 - mse: 18456616.0000 - val_loss: 1830.6810 - val_mae: 1830.6810 - val_mse: 19235552.0000\n",
            "Epoch 866/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1588.8712 - mae: 1588.8712 - mse: 18417582.0000 - val_loss: 1767.0808 - val_mae: 1767.0808 - val_mse: 22835738.0000\n",
            "Epoch 867/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1582.9286 - mae: 1582.9286 - mse: 19059116.0000 - val_loss: 1860.6986 - val_mae: 1860.6986 - val_mse: 21541108.0000\n",
            "Epoch 868/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1563.2782 - mae: 1563.2782 - mse: 18775532.0000 - val_loss: 1774.5120 - val_mae: 1774.5120 - val_mse: 21081634.0000\n",
            "Epoch 869/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1601.1763 - mae: 1601.1763 - mse: 19316024.0000 - val_loss: 1623.6377 - val_mae: 1623.6377 - val_mse: 19463746.0000\n",
            "Epoch 870/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1524.1799 - mae: 1524.1799 - mse: 18733166.0000 - val_loss: 2044.2830 - val_mae: 2044.2830 - val_mse: 19899090.0000\n",
            "Epoch 871/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1605.8418 - mae: 1605.8418 - mse: 19099438.0000 - val_loss: 1789.0946 - val_mae: 1789.0946 - val_mse: 19413720.0000\n",
            "Epoch 872/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1539.0315 - mae: 1539.0315 - mse: 18589358.0000 - val_loss: 1834.3214 - val_mae: 1834.3214 - val_mse: 21014800.0000\n",
            "Epoch 873/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1573.6787 - mae: 1573.6787 - mse: 19055476.0000 - val_loss: 1808.5209 - val_mae: 1808.5209 - val_mse: 21395836.0000\n",
            "Epoch 874/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1552.0399 - mae: 1552.0399 - mse: 18841600.0000 - val_loss: 1764.7235 - val_mae: 1764.7235 - val_mse: 19753866.0000\n",
            "Epoch 875/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1588.3302 - mae: 1588.3302 - mse: 19413880.0000 - val_loss: 1605.1818 - val_mae: 1605.1818 - val_mse: 19776646.0000\n",
            "Epoch 876/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1587.9740 - mae: 1587.9740 - mse: 19110722.0000 - val_loss: 1617.3921 - val_mae: 1617.3921 - val_mse: 20531222.0000\n",
            "Epoch 877/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1560.2471 - mae: 1560.2471 - mse: 19152698.0000 - val_loss: 1638.6951 - val_mae: 1638.6951 - val_mse: 19723980.0000\n",
            "Epoch 878/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1556.5311 - mae: 1556.5311 - mse: 18982834.0000 - val_loss: 1603.4865 - val_mae: 1603.4865 - val_mse: 20635542.0000\n",
            "Epoch 879/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1546.5197 - mae: 1546.5197 - mse: 18628774.0000 - val_loss: 1691.4647 - val_mae: 1691.4647 - val_mse: 21563236.0000\n",
            "Epoch 880/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1581.6558 - mae: 1581.6558 - mse: 19091808.0000 - val_loss: 1744.5243 - val_mae: 1744.5243 - val_mse: 21155052.0000\n",
            "Epoch 881/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1571.7944 - mae: 1571.7944 - mse: 19061372.0000 - val_loss: 1639.0967 - val_mae: 1639.0967 - val_mse: 20453984.0000\n",
            "Epoch 882/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1578.6687 - mae: 1578.6687 - mse: 19384942.0000 - val_loss: 1678.8889 - val_mae: 1678.8889 - val_mse: 19615510.0000\n",
            "Epoch 883/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.2559 - mae: 1554.2559 - mse: 18698022.0000 - val_loss: 1744.4583 - val_mae: 1744.4583 - val_mse: 21245480.0000\n",
            "Epoch 884/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1559.5062 - mae: 1559.5062 - mse: 18777018.0000 - val_loss: 1724.1681 - val_mae: 1724.1681 - val_mse: 21939910.0000\n",
            "Epoch 885/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1563.3055 - mae: 1563.3055 - mse: 18751284.0000 - val_loss: 1655.1198 - val_mae: 1655.1198 - val_mse: 19542592.0000\n",
            "Epoch 886/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1555.5916 - mae: 1555.5916 - mse: 19064042.0000 - val_loss: 2252.2595 - val_mae: 2252.2595 - val_mse: 25203674.0000\n",
            "Epoch 887/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1559.9543 - mae: 1559.9543 - mse: 19011838.0000 - val_loss: 1550.1755 - val_mae: 1550.1755 - val_mse: 20278956.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 888/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1597.6456 - mae: 1597.6456 - mse: 19104410.0000 - val_loss: 1549.2819 - val_mae: 1549.2819 - val_mse: 20187566.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 889/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1530.9667 - mae: 1530.9667 - mse: 19088996.0000 - val_loss: 1569.1298 - val_mae: 1569.1298 - val_mse: 20671968.0000\n",
            "Epoch 890/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1588.0023 - mae: 1588.0023 - mse: 19145542.0000 - val_loss: 1829.0697 - val_mae: 1829.0697 - val_mse: 20291280.0000\n",
            "Epoch 891/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1539.7058 - mae: 1539.7058 - mse: 18926208.0000 - val_loss: 1734.4629 - val_mae: 1734.4629 - val_mse: 21819284.0000\n",
            "Epoch 892/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1537.7052 - mae: 1537.7052 - mse: 18807934.0000 - val_loss: 1758.0526 - val_mae: 1758.0526 - val_mse: 20839814.0000\n",
            "Epoch 893/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1532.3790 - mae: 1532.3790 - mse: 18832204.0000 - val_loss: 1698.1676 - val_mae: 1698.1676 - val_mse: 19785968.0000\n",
            "Epoch 894/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1585.1428 - mae: 1585.1428 - mse: 19007210.0000 - val_loss: 1787.6846 - val_mae: 1787.6846 - val_mse: 19456016.0000\n",
            "Epoch 895/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1587.5726 - mae: 1587.5726 - mse: 19184906.0000 - val_loss: 1616.5916 - val_mae: 1616.5916 - val_mse: 19696486.0000\n",
            "Epoch 896/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1602.4701 - mae: 1602.4701 - mse: 19230442.0000 - val_loss: 1775.3944 - val_mae: 1775.3944 - val_mse: 21514996.0000\n",
            "Epoch 897/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1546.5483 - mae: 1546.5483 - mse: 19044854.0000 - val_loss: 1758.0281 - val_mae: 1758.0281 - val_mse: 19595916.0000\n",
            "Epoch 898/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1551.2203 - mae: 1551.2203 - mse: 19009858.0000 - val_loss: 1582.7218 - val_mae: 1582.7218 - val_mse: 20573102.0000\n",
            "Epoch 899/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1546.6958 - mae: 1546.6958 - mse: 18782736.0000 - val_loss: 2034.4524 - val_mae: 2034.4524 - val_mse: 21428362.0000\n",
            "Epoch 900/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1604.1433 - mae: 1604.1433 - mse: 19186470.0000 - val_loss: 1601.5463 - val_mae: 1601.5463 - val_mse: 19724578.0000\n",
            "Epoch 901/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1583.4568 - mae: 1583.4568 - mse: 19119548.0000 - val_loss: 1680.1454 - val_mae: 1680.1454 - val_mse: 19603200.0000\n",
            "Epoch 902/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1531.1906 - mae: 1531.1906 - mse: 18629848.0000 - val_loss: 1741.5184 - val_mae: 1741.5184 - val_mse: 19495666.0000\n",
            "Epoch 903/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1576.2411 - mae: 1576.2411 - mse: 19063346.0000 - val_loss: 1742.1918 - val_mae: 1742.1918 - val_mse: 21068702.0000\n",
            "Epoch 904/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1559.2090 - mae: 1559.2090 - mse: 18999104.0000 - val_loss: 1579.3053 - val_mae: 1579.3053 - val_mse: 20742756.0000\n",
            "Epoch 905/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1530.5419 - mae: 1530.5419 - mse: 18443054.0000 - val_loss: 1584.8439 - val_mae: 1584.8439 - val_mse: 20721968.0000\n",
            "Epoch 906/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1559.1249 - mae: 1559.1249 - mse: 18591590.0000 - val_loss: 1870.4658 - val_mae: 1870.4658 - val_mse: 22446718.0000\n",
            "Epoch 907/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1568.5337 - mae: 1568.5337 - mse: 19226170.0000 - val_loss: 1737.7368 - val_mae: 1737.7368 - val_mse: 19444588.0000\n",
            "Epoch 908/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1579.9036 - mae: 1579.9036 - mse: 19077570.0000 - val_loss: 1663.2245 - val_mae: 1663.2245 - val_mse: 20977396.0000\n",
            "Epoch 909/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1553.1028 - mae: 1553.1028 - mse: 18867000.0000 - val_loss: 1561.3101 - val_mae: 1561.3101 - val_mse: 20254632.0000\n",
            "Epoch 910/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1559.0425 - mae: 1559.0425 - mse: 18855638.0000 - val_loss: 1850.9635 - val_mae: 1850.9635 - val_mse: 20212484.0000\n",
            "Epoch 911/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1561.8636 - mae: 1561.8636 - mse: 18998942.0000 - val_loss: 1711.7517 - val_mae: 1711.7517 - val_mse: 19467424.0000\n",
            "Epoch 912/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1545.0764 - mae: 1545.0764 - mse: 18791530.0000 - val_loss: 1672.0885 - val_mae: 1672.0885 - val_mse: 19801596.0000\n",
            "Epoch 913/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1597.2008 - mae: 1597.2008 - mse: 19025796.0000 - val_loss: 1674.9899 - val_mae: 1674.9899 - val_mse: 20639276.0000\n",
            "Epoch 914/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1527.8633 - mae: 1527.8633 - mse: 18671746.0000 - val_loss: 2191.6897 - val_mae: 2191.6897 - val_mse: 24255130.0000\n",
            "Epoch 915/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1576.0173 - mae: 1576.0173 - mse: 18978424.0000 - val_loss: 1591.1204 - val_mae: 1591.1204 - val_mse: 20219346.0000\n",
            "Epoch 916/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1527.3878 - mae: 1527.3878 - mse: 18737776.0000 - val_loss: 1693.6830 - val_mae: 1693.6830 - val_mse: 19594162.0000\n",
            "Epoch 917/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1538.9160 - mae: 1538.9160 - mse: 18612092.0000 - val_loss: 1573.0676 - val_mae: 1573.0676 - val_mse: 19956960.0000\n",
            "Epoch 918/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1570.6342 - mae: 1570.6342 - mse: 18760324.0000 - val_loss: 1730.6323 - val_mae: 1730.6323 - val_mse: 19128770.0000\n",
            "Epoch 919/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1551.4594 - mae: 1551.4594 - mse: 18848474.0000 - val_loss: 1707.4448 - val_mae: 1707.4448 - val_mse: 19407660.0000\n",
            "Epoch 920/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1573.4376 - mae: 1573.4376 - mse: 18977850.0000 - val_loss: 1636.6451 - val_mae: 1636.6451 - val_mse: 20643586.0000\n",
            "Epoch 921/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1532.6339 - mae: 1532.6339 - mse: 18844376.0000 - val_loss: 1656.6025 - val_mae: 1656.6025 - val_mse: 20218332.0000\n",
            "Epoch 922/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1572.8271 - mae: 1572.8271 - mse: 18829212.0000 - val_loss: 1584.5485 - val_mae: 1584.5485 - val_mse: 20438006.0000\n",
            "Epoch 923/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1552.5171 - mae: 1552.5171 - mse: 18671368.0000 - val_loss: 1581.8251 - val_mae: 1581.8251 - val_mse: 20451632.0000\n",
            "Epoch 924/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1565.3866 - mae: 1565.3866 - mse: 19237600.0000 - val_loss: 1624.4229 - val_mae: 1624.4229 - val_mse: 19260524.0000\n",
            "Epoch 925/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1512.1978 - mae: 1512.1978 - mse: 18443060.0000 - val_loss: 1849.3815 - val_mae: 1849.3815 - val_mse: 21404634.0000\n",
            "Epoch 926/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1586.1387 - mae: 1586.1387 - mse: 18965994.0000 - val_loss: 1538.7899 - val_mae: 1538.7899 - val_mse: 19500400.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 927/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1562.1405 - mae: 1562.1405 - mse: 18873378.0000 - val_loss: 1989.0529 - val_mae: 1989.0529 - val_mse: 22190248.0000\n",
            "Epoch 928/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1563.8636 - mae: 1563.8636 - mse: 18893484.0000 - val_loss: 1630.5728 - val_mae: 1630.5728 - val_mse: 20121980.0000\n",
            "Epoch 929/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1555.2435 - mae: 1555.2435 - mse: 18841686.0000 - val_loss: 1543.2924 - val_mae: 1543.2924 - val_mse: 20037844.0000\n",
            "Epoch 930/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1519.2059 - mae: 1519.2059 - mse: 18464344.0000 - val_loss: 1760.5555 - val_mae: 1760.5555 - val_mse: 22563608.0000\n",
            "Epoch 931/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1558.8446 - mae: 1558.8446 - mse: 19290936.0000 - val_loss: 1744.2892 - val_mae: 1744.2892 - val_mse: 20147944.0000\n",
            "Epoch 932/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1549.8611 - mae: 1549.8611 - mse: 18922892.0000 - val_loss: 1853.6156 - val_mae: 1853.6156 - val_mse: 19241196.0000\n",
            "Epoch 933/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1569.6162 - mae: 1569.6162 - mse: 19209896.0000 - val_loss: 1841.5699 - val_mae: 1841.5699 - val_mse: 21912404.0000\n",
            "Epoch 934/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1550.9578 - mae: 1550.9578 - mse: 18843920.0000 - val_loss: 1679.3777 - val_mae: 1679.3777 - val_mse: 20256794.0000\n",
            "Epoch 935/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1563.7113 - mae: 1563.7113 - mse: 19206212.0000 - val_loss: 1878.9294 - val_mae: 1878.9294 - val_mse: 19352438.0000\n",
            "Epoch 936/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1533.8698 - mae: 1533.8698 - mse: 18912392.0000 - val_loss: 1621.2418 - val_mae: 1621.2418 - val_mse: 19748240.0000\n",
            "Epoch 937/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1594.8214 - mae: 1594.8214 - mse: 19028130.0000 - val_loss: 1545.5028 - val_mae: 1545.5028 - val_mse: 20116676.0000\n",
            "Epoch 938/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1548.1754 - mae: 1548.1754 - mse: 18817184.0000 - val_loss: 1648.3358 - val_mae: 1648.3358 - val_mse: 20059732.0000\n",
            "Epoch 939/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1540.1854 - mae: 1540.1854 - mse: 19035092.0000 - val_loss: 1858.1589 - val_mae: 1858.1589 - val_mse: 19268978.0000\n",
            "Epoch 940/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1556.2483 - mae: 1556.2483 - mse: 18772928.0000 - val_loss: 2133.0549 - val_mae: 2133.0549 - val_mse: 19936144.0000\n",
            "Epoch 941/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1525.7402 - mae: 1525.7402 - mse: 18691400.0000 - val_loss: 1506.0399 - val_mae: 1506.0399 - val_mse: 19659510.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 942/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1549.5704 - mae: 1549.5704 - mse: 19008982.0000 - val_loss: 1902.3265 - val_mae: 1902.3265 - val_mse: 19311278.0000\n",
            "Epoch 943/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1568.0428 - mae: 1568.0428 - mse: 19017804.0000 - val_loss: 1505.3303 - val_mae: 1505.3303 - val_mse: 19981268.0000\n",
            "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
            "Epoch 944/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1562.6007 - mae: 1562.6007 - mse: 18958976.0000 - val_loss: 1676.7159 - val_mae: 1676.7159 - val_mse: 19281118.0000\n",
            "Epoch 945/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1524.9413 - mae: 1524.9413 - mse: 18439286.0000 - val_loss: 1925.3608 - val_mae: 1925.3608 - val_mse: 20253028.0000\n",
            "Epoch 946/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1550.1149 - mae: 1550.1149 - mse: 18777554.0000 - val_loss: 1562.3152 - val_mae: 1562.3152 - val_mse: 20486098.0000\n",
            "Epoch 947/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1540.5441 - mae: 1540.5441 - mse: 18673346.0000 - val_loss: 1833.2310 - val_mae: 1833.2310 - val_mse: 19739632.0000\n",
            "Epoch 948/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1556.0254 - mae: 1556.0254 - mse: 19046066.0000 - val_loss: 2422.8208 - val_mae: 2422.8208 - val_mse: 26124978.0000\n",
            "Epoch 949/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1583.6132 - mae: 1583.6132 - mse: 19006836.0000 - val_loss: 1832.3879 - val_mae: 1832.3879 - val_mse: 21380104.0000\n",
            "Epoch 950/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1537.6124 - mae: 1537.6124 - mse: 18763974.0000 - val_loss: 1606.1809 - val_mae: 1606.1809 - val_mse: 19417124.0000\n",
            "Epoch 951/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1553.1779 - mae: 1553.1779 - mse: 18726154.0000 - val_loss: 1661.6995 - val_mae: 1661.6995 - val_mse: 20337580.0000\n",
            "Epoch 952/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1543.1404 - mae: 1543.1404 - mse: 18999402.0000 - val_loss: 1592.1885 - val_mae: 1592.1885 - val_mse: 20432614.0000\n",
            "Epoch 953/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1577.5092 - mae: 1577.5092 - mse: 18920682.0000 - val_loss: 1609.2570 - val_mae: 1609.2570 - val_mse: 20545894.0000\n",
            "Epoch 954/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1543.9590 - mae: 1543.9590 - mse: 18879532.0000 - val_loss: 1787.5248 - val_mae: 1787.5248 - val_mse: 22146114.0000\n",
            "Epoch 955/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1560.2644 - mae: 1560.2644 - mse: 19273912.0000 - val_loss: 1648.4452 - val_mae: 1648.4452 - val_mse: 20519384.0000\n",
            "Epoch 956/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1550.5961 - mae: 1550.5961 - mse: 18802110.0000 - val_loss: 1625.1974 - val_mae: 1625.1974 - val_mse: 19176312.0000\n",
            "Epoch 957/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1568.1476 - mae: 1568.1476 - mse: 19037536.0000 - val_loss: 1959.4945 - val_mae: 1959.4945 - val_mse: 19285984.0000\n",
            "Epoch 958/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1561.8488 - mae: 1561.8488 - mse: 18771452.0000 - val_loss: 1559.8258 - val_mae: 1559.8258 - val_mse: 19588718.0000\n",
            "Epoch 959/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1549.6234 - mae: 1549.6234 - mse: 19126240.0000 - val_loss: 1677.6356 - val_mae: 1677.6356 - val_mse: 20920274.0000\n",
            "Epoch 960/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1561.9199 - mae: 1561.9199 - mse: 18911544.0000 - val_loss: 1701.9819 - val_mae: 1701.9819 - val_mse: 19132342.0000\n",
            "Epoch 961/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1540.1515 - mae: 1540.1515 - mse: 18850904.0000 - val_loss: 1830.0421 - val_mae: 1830.0421 - val_mse: 19666656.0000\n",
            "Epoch 962/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1550.5914 - mae: 1550.5914 - mse: 18916878.0000 - val_loss: 1613.1012 - val_mae: 1613.1012 - val_mse: 19491522.0000\n",
            "Epoch 963/1000\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1561.1504 - mae: 1561.1504 - mse: 18813620.0000 - val_loss: 1705.7919 - val_mae: 1705.7919 - val_mse: 19457124.0000\n",
            "Epoch 964/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1539.0781 - mae: 1539.0781 - mse: 18752960.0000 - val_loss: 1623.2570 - val_mae: 1623.2570 - val_mse: 20701182.0000\n",
            "Epoch 965/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1553.6621 - mae: 1553.6621 - mse: 18851860.0000 - val_loss: 1645.2592 - val_mae: 1645.2592 - val_mse: 20693122.0000\n",
            "Epoch 966/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1517.4524 - mae: 1517.4524 - mse: 18657906.0000 - val_loss: 1515.6077 - val_mae: 1515.6077 - val_mse: 19702342.0000\n",
            "Epoch 967/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1511.2227 - mae: 1511.2227 - mse: 18792050.0000 - val_loss: 1810.4781 - val_mae: 1810.4781 - val_mse: 21320794.0000\n",
            "Epoch 968/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1578.2612 - mae: 1578.2612 - mse: 18679780.0000 - val_loss: 1509.5802 - val_mae: 1509.5802 - val_mse: 19959764.0000\n",
            "Epoch 969/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1520.3135 - mae: 1520.3135 - mse: 18851842.0000 - val_loss: 1912.7308 - val_mae: 1912.7308 - val_mse: 19359624.0000\n",
            "Epoch 970/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1543.3116 - mae: 1543.3116 - mse: 18871760.0000 - val_loss: 1697.7506 - val_mae: 1697.7506 - val_mse: 19611942.0000\n",
            "Epoch 971/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1585.8595 - mae: 1585.8595 - mse: 18983718.0000 - val_loss: 1815.6821 - val_mae: 1815.6821 - val_mse: 21937920.0000\n",
            "Epoch 972/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1529.5516 - mae: 1529.5516 - mse: 18639106.0000 - val_loss: 1833.7875 - val_mae: 1833.7875 - val_mse: 19905008.0000\n",
            "Epoch 973/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1510.4696 - mae: 1510.4696 - mse: 18554922.0000 - val_loss: 1605.9032 - val_mae: 1605.9032 - val_mse: 20198950.0000\n",
            "Epoch 974/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1535.4219 - mae: 1535.4219 - mse: 18845618.0000 - val_loss: 1851.4374 - val_mae: 1851.4374 - val_mse: 21750014.0000\n",
            "Epoch 975/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1530.1517 - mae: 1530.1517 - mse: 18716146.0000 - val_loss: 2043.2406 - val_mae: 2043.2406 - val_mse: 22925102.0000\n",
            "Epoch 976/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1541.5168 - mae: 1541.5168 - mse: 18997382.0000 - val_loss: 1702.5485 - val_mae: 1702.5485 - val_mse: 21192268.0000\n",
            "Epoch 977/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1563.4082 - mae: 1563.4082 - mse: 18783316.0000 - val_loss: 1952.0980 - val_mae: 1952.0980 - val_mse: 23053082.0000\n",
            "Epoch 978/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1571.2909 - mae: 1571.2909 - mse: 19024772.0000 - val_loss: 1705.6018 - val_mae: 1705.6018 - val_mse: 19504518.0000\n",
            "Epoch 979/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1557.8969 - mae: 1557.8969 - mse: 18985324.0000 - val_loss: 1651.4185 - val_mae: 1651.4185 - val_mse: 19491150.0000\n",
            "Epoch 980/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1494.3204 - mae: 1494.3204 - mse: 18433564.0000 - val_loss: 1569.2932 - val_mae: 1569.2932 - val_mse: 20380672.0000\n",
            "Epoch 981/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1536.9054 - mae: 1536.9054 - mse: 18788558.0000 - val_loss: 1621.6282 - val_mae: 1621.6282 - val_mse: 20892778.0000\n",
            "Epoch 982/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1551.1438 - mae: 1551.1438 - mse: 18865714.0000 - val_loss: 1511.9767 - val_mae: 1511.9767 - val_mse: 19983498.0000\n",
            "Epoch 983/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1547.8777 - mae: 1547.8777 - mse: 18913594.0000 - val_loss: 1624.2462 - val_mae: 1624.2462 - val_mse: 19576062.0000\n",
            "Epoch 984/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1526.7416 - mae: 1526.7416 - mse: 18499866.0000 - val_loss: 1790.9598 - val_mae: 1790.9598 - val_mse: 20188978.0000\n",
            "Epoch 985/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1554.7754 - mae: 1554.7754 - mse: 18900246.0000 - val_loss: 1564.4454 - val_mae: 1564.4454 - val_mse: 20217790.0000\n",
            "Epoch 986/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1528.3491 - mae: 1528.3491 - mse: 18585266.0000 - val_loss: 1529.4474 - val_mae: 1529.4474 - val_mse: 20223310.0000\n",
            "Epoch 987/1000\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1561.3085 - mae: 1561.3085 - mse: 18888634.0000 - val_loss: 1665.7200 - val_mae: 1665.7200 - val_mse: 20557564.0000\n",
            "Epoch 988/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1532.5164 - mae: 1532.5164 - mse: 18779194.0000 - val_loss: 1690.8455 - val_mae: 1690.8455 - val_mse: 19799060.0000\n",
            "Epoch 989/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1553.8945 - mae: 1553.8945 - mse: 18792936.0000 - val_loss: 1701.9396 - val_mae: 1701.9396 - val_mse: 20935852.0000\n",
            "Epoch 990/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1509.0530 - mae: 1509.0530 - mse: 18620360.0000 - val_loss: 1576.7704 - val_mae: 1576.7704 - val_mse: 20256064.0000\n",
            "Epoch 991/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1509.1260 - mae: 1509.1260 - mse: 18645658.0000 - val_loss: 1629.1874 - val_mae: 1629.1874 - val_mse: 19948686.0000\n",
            "Epoch 992/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1522.5901 - mae: 1522.5901 - mse: 18748238.0000 - val_loss: 1734.7308 - val_mae: 1734.7308 - val_mse: 19202066.0000\n",
            "Epoch 993/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1544.9515 - mae: 1544.9515 - mse: 18752600.0000 - val_loss: 1676.8317 - val_mae: 1676.8317 - val_mse: 20211126.0000\n",
            "Epoch 994/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1537.4452 - mae: 1537.4452 - mse: 18708448.0000 - val_loss: 1978.3346 - val_mae: 1978.3346 - val_mse: 19586638.0000\n",
            "Epoch 995/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1556.8893 - mae: 1556.8893 - mse: 18734036.0000 - val_loss: 1729.2399 - val_mae: 1729.2399 - val_mse: 21305544.0000\n",
            "Epoch 996/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1517.5630 - mae: 1517.5630 - mse: 18646050.0000 - val_loss: 1740.9159 - val_mae: 1740.9159 - val_mse: 21926420.0000\n",
            "Epoch 997/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1581.9478 - mae: 1581.9478 - mse: 19111338.0000 - val_loss: 1612.1401 - val_mae: 1612.1401 - val_mse: 20563838.0000\n",
            "Epoch 998/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1533.8693 - mae: 1533.8693 - mse: 18590824.0000 - val_loss: 1676.9839 - val_mae: 1676.9839 - val_mse: 20590170.0000\n",
            "Epoch 999/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1543.7455 - mae: 1543.7455 - mse: 18763122.0000 - val_loss: 2046.9105 - val_mae: 2046.9105 - val_mse: 22856226.0000\n",
            "Epoch 1000/1000\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1512.5273 - mae: 1512.5273 - mse: 18791122.0000 - val_loss: 1603.1453 - val_mae: 1603.1453 - val_mse: 20574028.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "d11b15ab-ac72-4e23-e2f3-93920567821e"
      },
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 - 0s - loss: 2187.3862 - mae: 2187.3862 - mse: 35214788.0000\n",
            "Testing set Mean Abs Error: 2187.39 expenses\n",
            "You passed the challenge. Great job!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}